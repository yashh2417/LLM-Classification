{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bae01c94-ce56-4cc5-9c7b-f5b9494105ce",
   "metadata": {},
   "source": [
    "# FINETUNING FOR CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2436e40-2612-46c6-be07-525a3fcd7a5e",
   "metadata": {},
   "source": [
    "# Stage 1: Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed46ecee-afa0-4b95-bbb7-0f32b1d94df1",
   "metadata": {},
   "source": [
    "## A. Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394fef2f-29e6-429a-9cdf-c1e70866cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Create an unverified SSL context\n",
    "    ssl_context = ssl._create_unverified_context()\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a61970-fee1-4b46-9988-0b1712e84c91",
   "metadata": {},
   "source": [
    "After executing the preceding code, the dataset is saved as a tab-separated text file, SMSSpamCollection.tsv, in the sms_spam_collection folder.\n",
    "\n",
    "We can load it into a pandas DataFrame as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288117a3-bd53-4dd6-b6d2-162c9ea7afbf",
   "metadata": {},
   "source": [
    "## B. Preprocess the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a5edb47-d5a2-415e-921a-6951a7bb8db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ã¼ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will Ã¼ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c40c32-2be7-4187-b487-cd3782c7bc43",
   "metadata": {},
   "source": [
    "When we check the class distribution, we see that the data contains \"ham\" (i.e., \"not spam\") much more frequently than \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e68452-39b8-41d9-baf2-c3f20e93688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa61b4-7a79-49c5-9b50-1303bcc8ec22",
   "metadata": {},
   "source": [
    "For simplicity, and because we prefer a small dataset for educational purposes anyway (it will make it possible to finetune the LLM faster), we subsample (undersample) the dataset so that it contains 747 instances from each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e02efd-a00d-4e24-9e51-f3665c8a9b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    \n",
    "    # Count the instances of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "    \n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "    \n",
    "    # Combine ham \"subset\" with \"spam\"\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35909da8-94b2-44fa-888b-d7ed596e532a",
   "metadata": {},
   "source": [
    "After executing the previous code to balance the dataset, we can see that we now have equal amounts of spam and non-spam messages:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba4e70d-fec7-4c36-bcc1-853a0be5e575",
   "metadata": {},
   "source": [
    "Next, we convert the \"string\" class labels \"ham\" and \"spam\" into integer class labels 0 and 1, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94cb51e9-111f-429a-8370-0a3b7633aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f86c1-4c24-46ad-9267-3b4d772c86c4",
   "metadata": {},
   "source": [
    "This process is similar to converting text into token IDs.\n",
    "\n",
    "However, instead of using the GPT vocabulary, which consists of more than 50,000 words, we are dealing with just two token IDs: 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482aaf1b-dc1f-472c-8a45-c641fa869e5f",
   "metadata": {},
   "source": [
    "We create a random_split function to split the dataset into three parts: 70% for training, 10% for validation, and 20% for testing.\n",
    "\n",
    "(These ratios are common in machine learning to train, adjust, and evaluate models.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b03501-bb12-477a-a524-eb69826eb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "269eed1e-f218-4259-8d18-a4f042189de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1045\n",
      "149\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df))\n",
    "print(len(validation_df))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a229553-7b3b-4dc0-bb30-9ba5b56775cb",
   "metadata": {},
   "source": [
    "Additionally, we save the dataset as CSV (comma-separated value) files, which we can reuse later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be00afbb-175a-435f-93e9-43cb535c8a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f79e36c-191e-48db-bf0f-96e998a774c3",
   "metadata": {},
   "source": [
    "We have to make sure that: **INPUT TEXT** **-->** **TOKENIZE** **-->** **ENSURE THAT ALL SENTENCES ARE OF SAME LENGHT**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5b6e08-fe8d-4086-9889-303aeb4c2055",
   "metadata": {},
   "source": [
    "We use padding of **endofword** token with **20256** token id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd26adf-b515-4119-945b-35226353be86",
   "metadata": {},
   "source": [
    "## C. Creating Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b944db7-3edd-4c89-b5c8-a394325f2681",
   "metadata": {},
   "source": [
    "Previously, we utilized a sliding window technique to generate uniformly sized text chunks, which were then grouped into batches for more efficient model training. Each chunk functioned as an individual training instance\n",
    "\n",
    "In the case of email spam classification, have two primary options:\n",
    "\n",
    "(1) Truncate all messages to the length of the shortest message in the dataset or batch.\n",
    "\n",
    "(2) Pad all messages to the length of the longest message in the dataset or batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf705d-223b-4607-8c54-76a0bd83e924",
   "metadata": {},
   "source": [
    "Option 1 is computationally cheaper, but it may result in significant information loss if shorter messages are much smaller than the average or longest messages, potentially reducing model performance.\n",
    "\n",
    "So, we opt for the second option, which preserves the entire content of all messages.\n",
    "\n",
    "To implement option 2, where all messages are padded to the length of the longest message in the dataset, we add padding tokens to all shorter messages.\n",
    "\n",
    "For this purpose, we use \"<|endoftext|>\" as a padding token, as discussed in chapter 2.\n",
    "\n",
    "However, instead of appending the string \"<|endoftext|>\" to each of the text messages directly, we can add the token ID corresponding to \"<|endoftext|>\" to the encoded text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324d6f49-990c-426b-8942-6b6d8436291d",
   "metadata": {},
   "source": [
    "As we have seen earlier, we first need to implement a PyTorch Dataset, which specifies how the data is loaded and processed, before we can instantiate the data loaders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210a99b-987e-447f-893b-fff207781476",
   "metadata": {},
   "source": [
    "For this purpose, we define the SpamDataset class.\n",
    "\n",
    "This SpamDataset class handles several key tasks: it identifies the longest sequence in the training dataset, encodes the text messages, and ensures that all other sequences are padded with a padding token to match the length of the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f23764d9-74e5-49e3-8cf5-a715437223aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Pre-tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            \n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbdb66-081f-4f22-99e3-222fbbc3c02e",
   "metadata": {},
   "source": [
    "Step 1: Pre-tokenize texts\n",
    "\n",
    "Step 2: Truncate sequences if they are longer than max_length\n",
    "\n",
    "Step 3: Pad sequences to the longest sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ff1db-1a64-4bec-a6a1-01a4bb2a5abc",
   "metadata": {},
   "source": [
    "The SpamDataset class loads data from the CSV files we created earlier, tokenizes the text using the GPT-2 tokenizer from tiktoken and allows us to pad or truncate the sequences to a uniform length determined by either the longest sequence or a predefined maximum length.\n",
    "\n",
    "This ensures each input tensor is of the same size, which is necessary to create the batches in the training data loader we implement next:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "099fc28c-0376-47b5-a0c4-18cbe51257c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31b6cd86-04ba-4226-87b6-3dafe2c7d294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [15496, 11, 995, 0, 50169, 233]\n",
      "Decoded text: Hello, world! ðŸ‘‹\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Choose the encoding (e.g., for GPT-2)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = \"Hello, world! ðŸ‘‹\"\n",
    "\n",
    "# Encode: Convert text to list of token integers\n",
    "tokens = tokenizer.encode(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Decode: Convert tokens back to text\n",
    "decoded = tokenizer.decode(tokens)\n",
    "print(\"Decoded text:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab25f3a-c65a-494b-aae6-5ee9bb3c38ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3590d803-13bf-4daf-aa98-6fb7329e8281",
   "metadata": {},
   "source": [
    "The code outputs 120, showing that the longest sequence contains no more than 120 tokens, a common length for text messages.\n",
    "\n",
    "It's worth noting that the model can handle sequences of up to 1,024 tokens, given its context length limit.\n",
    "\n",
    "If your dataset includes longer texts, you can pass max_length=1024 when creating the training dataset in the preceding code to ensure that the data does not exceed the model's supported input (context) length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5271abb2-f527-4343-b12c-3fd0570c9525",
   "metadata": {},
   "source": [
    "Next, we pad the validation and test sets to match the length of the longest training sequence.\n",
    "\n",
    "It's important to note that any validation and test set samples exceeding the length of the longest training example are truncated using encoded_text[:self.max_length] in the SpamDataset code we defined earlier.\n",
    "\n",
    "This truncation is optional; you could also set max_length=None for both validation and test sets, provided there are no sequences exceeding 1,024 tokens in these sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de7b4cda-9b80-4b13-a08a-a7282a3edbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(val_dataset.max_length)\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc42235-8887-493f-8004-465febd1b9b3",
   "metadata": {},
   "source": [
    "Using the datasets as inputs, we can instantiate the data loaders similarly to what we did earlier.\n",
    "\n",
    "However, in this case, the targets represent class labels rather than the next tokens in the text.\n",
    "\n",
    "For instance, choosing a batch size of 8, each batch will consist of 8 training examples of length 120 and the corresponding class label of each example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "164d89bb-b245-4b3f-a8f9-4ec6120f9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c10200a-f83f-4cbf-bc3a-816a4b3253c9",
   "metadata": {},
   "source": [
    "To ensure that the data loaders are working and are indeed returning batches of the expected size, we iterate over the training loader and then print the tensor dimensions of the last batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd85b8fd-8548-4030-b706-86e66969a593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb9be4a-a1df-4ba2-8ed1-7cbb01a9f5be",
   "metadata": {},
   "source": [
    "As we can see, the input batches consist of 8 training examples with 120 tokens each, as expected.\n",
    "\n",
    "The label tensor stores the class labels corresponding to the 8 training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b432a3-b2cd-4aad-b871-288583291549",
   "metadata": {},
   "source": [
    "Lastly, to get an idea of the dataset size, let's print the total number of batches in each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2d23d1-f2d8-4591-803d-50e3cd228950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f196d937-ffa3-4f24-b767-5a596d98d30b",
   "metadata": {},
   "source": [
    "This concludes the data preparation. Next, we will prepare the model for finetuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2c237-cf8a-4ff9-a3d9-88b5d75d37fa",
   "metadata": {},
   "source": [
    "# Stage 2: Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc82631-db7d-40aa-903f-98614a372e98",
   "metadata": {},
   "source": [
    "## A. Initialize Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d09c8c4-5692-4696-941f-ccbc211bc981",
   "metadata": {},
   "source": [
    "INITIALIZING A MODEL WITH PRETRAINED WEIGHTS:\n",
    "\n",
    "In this section, we prepare the model we will use for the classification-finetuning to identify spam messages.\n",
    "\n",
    "We start with initializing the pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441fde0-e157-4853-9584-9c13d5ee00f3",
   "metadata": {},
   "source": [
    "### LOADING PRETRAINED WEIGHTS FROM OPENAI"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36104316-d28b-40b0-a558-094703293de2",
   "metadata": {},
   "source": [
    "This approach allowed us to focus on the fundamentals without the need for extensive time and computational resources.\n",
    "\n",
    "Fortunately, OpenAI openly shared the weights of their GPT-2 models, thus eliminating the need to invest tens to hundreds of thousands of dollars in retraining the model on a large corpus ourselves."
   ]
  },
  {
   "cell_type": "raw",
   "id": "79dbcd68-6148-4ddc-8b62-e0e4bf3f9e42",
   "metadata": {},
   "source": [
    "Note that OpenAI originally saved the GPT-2 weights via TensorFlow, which we have to install to load the weights in Python.\n",
    "\n",
    "Moreover, the following code will use a progress bar tool called tqdm to track the download process, which we also have to install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "555cd70f-ea52-435d-ac5c-a0b47b43e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in ./llm-classification/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: tqdm in ./llm-classification/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (80.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./llm-classification/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./llm-classification/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./llm-classification/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./llm-classification/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./llm-classification/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./llm-classification/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./llm-classification/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./llm-classification/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./llm-classification/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in ./llm-classification/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in ./llm-classification/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in ./llm-classification/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./llm-classification/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./llm-classification/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./llm-classification/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./llm-classification/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b47e122-abc2-440d-a473-bd099a589250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "tqdm version: 4.66.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"tqdm version:\", tqdm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa05812-c970-4bee-988c-32f1d5eb2aab",
   "metadata": {},
   "source": [
    "We download the gpt_download.py Python module directly from this chapter's online repository"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e129d6f-ad01-45ca-9385-a2a22f0bdfa1",
   "metadata": {},
   "source": [
    "We can now import the download_and_load_gpt2 function from the gpt_download.py file as follows, which will load the GPT-2 architecture settings (settings) and weight parameters (params) into our Python session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af6a62fa-344a-47e8-b848-253a7a2fee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download3 import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d784a1f4-b407-4110-bfe8-d421ee61c24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38ef88d2-b4e4-487b-9d4d-4f3ebdef3729",
   "metadata": {},
   "source": [
    "After the execution of the previous code has been completed, let's inspect the contents of settings and params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bd7b612-929a-411e-8806-1df47349edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b4400a35-0ef2-496e-8beb-9904ab201082",
   "metadata": {},
   "source": [
    "Both settings and params are Python dictionaries. The settings dictionary stores the LLM architecture settings similarly to our manually defined GPT_CONFIG_124M settings.\n",
    "\n",
    "The params dictionary contains the actual weight tensors.\n",
    "\n",
    "Note that we only printed the dictionary keys because printing the weight contents would take up too much screen space"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1f4f414-a45a-459d-9844-31c88b4a1386",
   "metadata": {},
   "source": [
    "We can inspect these weight tensors by printing the whole dictionary via print(params) or by selecting individual tensors via the respective dictionary keys, for example, the embedding layer weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b3c76e9-17b6-48b3-a498-ad279738bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d4a9b39-5077-46d0-b4da-b3ff0e470682",
   "metadata": {},
   "source": [
    "We downloaded and loaded the weights of the smallest GPT-2 model via the download_and_load_gpt2(model_size=\"124M\", ...) setting. However, note that OpenAI also shares the weights of larger models: \"355M\", \"774M\", and \"1558M\"."
   ]
  },
  {
   "cell_type": "raw",
   "id": "65b308c6-d413-4d97-a4fb-7928e256cad4",
   "metadata": {},
   "source": [
    "Above, we loaded the 124M GPT-2 model weights into Python, however we still need to transfer them into our GPTModel instance.\n",
    "\n",
    "First, we initialize a new GPTModel instance.\n",
    "\n",
    "Note that the original GPT model initialized the linear layers for the query, key, and value matrices in the multi-head attention module with bias vectors, which is not required or recommended; however, to be able to load the weights correctly, we have to enable these too by setting qkv_bias to True in our implementation, too.\n",
    "\n",
    "We are also using the 1024 token context length that was used by the original GPT-2 model(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb709ac-ef56-4f90-b436-2a205a4d44a4",
   "metadata": {},
   "source": [
    "### GPT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4190d983-ad41-42ce-9567-3fd82e493d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1839e327-a76a-4787-8e71-7b49ae433925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be6e97e1-2337-438a-bca9-c0547f78e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        return x\n",
    "        # 2*4*768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94af6cb3-14d8-402f-8ff2-1e4a98e31416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38f9acf-dcbe-4bba-a151-bfc9d71c3eeb",
   "metadata": {},
   "source": [
    "**Next, we define a load_weights_into_gpt function that loads the weights from the params dictionary into a GPTModel instance gpt:**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "526c54a7-5d32-45cc-907d-07ad0bd72ee2",
   "metadata": {},
   "source": [
    "Step 1: Setting the model's positional and token embedding weights to those specified in params.\n",
    "\n",
    "Step 2: Iterate over each transformer block in the model.\n",
    "\n",
    "Step 3: The np.split function is used to divide the attention and bias weights into three equal parts for the query, key, and value components.\n",
    "\n",
    "Step 4: The original GPT-2 model by OpenAI reused the token embedding weights in the output layer to reduce the total number of parameters, which is a concept known as weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01dbeb3f-8032-4a4c-b677-7a1c5a95fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1146274a-982b-4d63-a79f-40c968e8f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e87b3ef-4913-48f9-a6f4-4b0658b12dac",
   "metadata": {},
   "source": [
    "In the load_weights_into_gpt function, we carefully match the weights from OpenAI's implementation with our GPTModel implementation.\n",
    "\n",
    "To pick a specific example, OpenAI stored the weight tensor for the output projection layer for the first transformer block as params[\"blocks\"][0][\"attn\"][\"c_proj\"][\"w\"].\n",
    "\n",
    "In our implementation, this weight tensor corresponds to gpt.trf_blocks[b].att.out_proj.weight, where gpt is a GPTModel instance."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d168eaf-1211-43a3-bcc4-2325671a3e45",
   "metadata": {},
   "source": [
    "Developing the load_weights_into_gpt function took a lot of guesswork since OpenAI used a slightly different naming convention from ours.\n",
    "\n",
    "However, the assign function would alert us if we try to match two tensors with different dimensions.\n",
    "\n",
    "Also, if we made a mistake in this function, we would notice this as the resulting GPT model would be unable to produce coherent text."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a866f99d-ab3e-478c-9b65-870710a90d80",
   "metadata": {},
   "source": [
    "Let's now try the load_weights_into_gpt out in practice and load the OpenAI model weights into our GPTModel instance gpt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35185a70-bbb6-4423-a6ca-cd9301bbb61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7e64c06-264d-4d39-926d-229939833974",
   "metadata": {},
   "source": [
    "Next, we import the download_and_load_gpt function from the gpt_download3.py file we downloaded earlier.\n",
    "\n",
    "Furthermore, we also reuse the GPTModel class and load_weights_into_gpt function from above to load the downloaded weights into the GPT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e976cfd-ac1c-41ca-9bfc-abff27810b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/urllib3/connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "\n",
    "from gpt_download3 import download_and_load_gpt2\n",
    "\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e205e05-9d51-4941-83e3-fa297773e615",
   "metadata": {},
   "source": [
    "To ensure that the model was loaded correctly, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57efb342-dd07-4ef8-9e54-48cf6a975910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    # idx is (batch, n_tokens) array of indices in the current context\n",
    "\n",
    "    ###Input batch:\n",
    " ###tensor([[6109, 3626, 6100,  345],\n",
    "        ##[6109, 1110, 6622,  257]])\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size\n",
    "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 tokens are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        # Get the predictions\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
    "        logits = logits[:, -1, :]  \n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
    "\n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
    "\n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cce5e1aa-58e3-45f0-8a43-64349b9bd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36ad5712-736a-45ca-9fa5-e4d96e3473bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c57007e6-3575-4e51-9958-43fb0225537f",
   "metadata": {},
   "source": [
    "Now, before we start finetuning the model as a spam classifier, let's see if the model can perhaps already classify spam messages by by prompting it with instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e44ea8c-87bd-481b-b040-41807cb379d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84305810-3199-4530-9645-0ff6f1a31d4c",
   "metadata": {},
   "source": [
    "Based on the output, it's apparent that the model struggles with following instructions.\n",
    "\n",
    "This is anticipated, as it has undergone only pretraining and lacks instruction-finetuning, which we will explore later\n",
    "\n",
    "The next section prepares the model for classification-finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4587ecf0-58e5-4a20-ba0a-622877a0ef5e",
   "metadata": {},
   "source": [
    "## ADDING A CLASSIFICATION HEAD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f22e81f-c360-49f0-92e2-27958b55de22",
   "metadata": {},
   "source": [
    "In this section, we modify the pretrained large language model to prepare it for classification-finetuning.\n",
    "\n",
    "To do this, we replace the original output layer, which maps the hidden representation to a vocabulary of 50,257, with a smaller output layer that maps to two classes: 0 (\"not spam\") and 1 (\"spam\"),"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5b14471-f69f-40ce-923e-798ca4e15d6f",
   "metadata": {},
   "source": [
    "We could technically use a single output node since we are dealing with a binary classification task.\n",
    "\n",
    "However, this would require modifying the loss function.\n",
    "\n",
    "Therefore, we choose a more general approach where the number of output nodes matches the number of classes.\n",
    "\n",
    "For example, for a 3-class problem, such as classifying news articles as \"Technology\", \"Sports\", or \"Politics\", we would use three output nodes, and so forth."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c08f2ed4-0bc4-4da2-b38a-6637a6cc9084",
   "metadata": {},
   "source": [
    "Before we attempt to construct the modified architecture, let's print the model architecture via print(model), which prints the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ebca9399-cc4a-4480-b039-a9380a85a253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb483e8d-39b8-4683-aa2f-e19c4a3089b9",
   "metadata": {},
   "source": [
    "Above, we can see the GPT architecture neatly laid out.\n",
    "\n",
    "As discussed earlier, the GPTModel consists of embedding layers followed by 12 identical transformer blocks (only the last block is shown for brevity), followed by a final LayerNorm and the output layer, out_head."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c644a428-216e-4d14-ac0e-02414f2f82fe",
   "metadata": {},
   "source": [
    "Next, we replace the out_head with a new output layer that we will finetune."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8df92f2-36c1-47a8-9cbd-c35132707631",
   "metadata": {},
   "source": [
    "To get the model ready for classification-finetuning, we first freeze the model, meaning that we make all layers non-trainable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afcfb73f-b2da-4eee-b301-19f1639aff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ffbcdd4-9d39-4144-9938-3c820039a4a4",
   "metadata": {},
   "source": [
    "Then, we replace the output layer (model.out_head), which originally maps the layer inputs to 50,257 dimensions (the size of the vocabulary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e72ed04c-b972-47ad-8162-dd573e46b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3de90f4a-e567-4fb2-aa54-2926e3b9d4a9",
   "metadata": {},
   "source": [
    "Note that in the preceding code, we use BASE_CONFIG[\"emb_dim\"], which is equal to 768 in the \"gpt2-small (124M)\" model, to keep the code below more general.\n",
    "\n",
    "This means we can also use the same code to work with the larger GPT-2 model variants.\n",
    "\n",
    "This new model.out_head output layer has its requires_grad attribute set to True by default, which means that it's the only layer in the model that will be updated during training."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0fdda08-eecf-423b-baf2-d937f9103af5",
   "metadata": {},
   "source": [
    "Additionally, we configure the last transformer block and the final LayerNorm module, which connects this block to the output layer, to be trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "100965ff-710a-4242-9447-6ed323e3b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37e835df-89d0-476f-8529-31d4fa2aae92",
   "metadata": {},
   "source": [
    "Even though we added a new output layer and marked certain layers as trainable or nontrainable, we can still use this model in a similar way to previous chapters.\n",
    "\n",
    "For instance, we can feed it an example text identical to how we have done it in earlier chapters. For example, consider the following example text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dec983c-a300-4689-97ef-9eba8fc5625e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91889f20-1974-4c2c-af07-6ed62c2bd188",
   "metadata": {},
   "source": [
    "Then, we can pass the encoded token IDs to the model as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c803f4b8-6537-4f04-9fc4-f422d6009185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9803c1f-c12d-42f4-9733-6cb64054951c",
   "metadata": {},
   "source": [
    "In earlier chapters, a similar input would have produced an output tensor of [1, 4, 50257], where 50,257 represents the vocabulary size.\n",
    "\n",
    "As in previous chapters, the number of output rows corresponds to the number of input tokens (in this case, 4).\n",
    "\n",
    "However, each output's embedding dimension (the number of columns) is now reduced to 2 instead of 50,257 since we replaced the output layer of the model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d459df0-4acf-41ef-8832-bd08722ce99b",
   "metadata": {},
   "source": [
    "Remember that we are interested in finetuning this model so that it returns a class label that indicates whether a model input is spam or not spam.\n",
    "\n",
    "To achieve this, we don't need to finetune all 4 output rows but can focus on a single output token.\n",
    "\n",
    "In particular, we will focus on the last row corresponding to the last output token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97d2f03-6738-4218-9f8c-ea4f33765d87",
   "metadata": {},
   "source": [
    "To extract the last output token, from the output tensor, we use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9477d0d1-c12b-4d1b-843f-ba050e322a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49b69a0e-cda3-4dbd-b915-bf9964233421",
   "metadata": {},
   "source": [
    "Having modified the model, the next section will detail the process of transforming the last token into class label predictions and calculate the model's initial prediction accuracy.\n",
    "\n",
    "Following this, we will finetune the model for the spam classification task in the subsequent section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c516b-60ea-4bd1-aec3-5e47a0b17c47",
   "metadata": {},
   "source": [
    "## Calculating Classification Loss and Accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14779b8d-d239-4c21-b6a4-b9b943d0381c",
   "metadata": {},
   "source": [
    "So far in this chapter, we have prepared the dataset, loaded a pretrained model, and modified it for classification-finetuning.\n",
    "\n",
    "Before we proceed with the finetuning itself, only one small part remains: implementing the model evaluation functions used during finetuning,"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3306b85a-116d-41e5-b8ca-6f83475b1088",
   "metadata": {},
   "source": [
    "Before implementing the evaluation utilities, let's briefly discuss how we convert the model outputs into class label predictions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0bdeec4-7261-4b8d-a4d4-01c2bab94a71",
   "metadata": {},
   "source": [
    "In the previous chapter, we computed the token ID of the next token generated by the LLM by converting the 50,257 outputs into probabilities via the softmax function and then returning the position of the highest probability via the argmax function.\n",
    "\n",
    "In this chapter, we take the same approach to calculate whether the model outputs a \"spam\" or \"not spam\" prediction for a given input, with the only difference being that we work with 2-dimensional instead of 50,257-dimensional outputs."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cb8d4b3-0404-4132-a15f-336880b69ee4",
   "metadata": {},
   "source": [
    "Let's consider the last token output from the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62693b3f-ae5e-4368-8d13-213634b90406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bbdd196-4d47-40d0-992b-9ccfa791620d",
   "metadata": {},
   "source": [
    "We can obtain the class label via the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f8f61e9-3714-4e35-9dec-e8acb0f48a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.0598e-04, 9.9949e-01]])\n",
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "print(probas)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "148b7cb6-865d-4898-bc68-19b71060cc23",
   "metadata": {},
   "source": [
    "In this case, the code returns 1, meaning the model predicts that the input text is \"spam.\"\n",
    "\n",
    "Using the softmax function here is optional because the largest outputs directly correspond to the highest probability scores.\n",
    "\n",
    "Hence, we can simplify the code as follows, without using softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81dd8f34-3b8f-4db8-8e88-ea327b53b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69620753-4d6d-4ab5-870b-ecd00f2a1732",
   "metadata": {},
   "source": [
    "This concept can be used to compute the so-called classification accuracy, which measures the percentage of correct predictions across a dataset."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a661728c-0dfd-4a11-8a09-822cf142fd6e",
   "metadata": {},
   "source": [
    "To determine the classification accuracy, we apply the argmax-based prediction code to all examples in the dataset and calculate the proportion of correct predictions by defining a calc_accuracy_loader function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa4332bd-3079-4d7f-bab7-da1025f2674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f2d091a-dd78-42bc-8a30-8ebba1c27b67",
   "metadata": {},
   "source": [
    "Let's use the function to determine the classification accuracies across various datasets estimated from 10 batches for efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4f02c12-4cbf-4fa1-804c-540c6e32f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on mps device.\n",
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "997c45dc-ae76-4105-8afa-fe3d5d3adfea",
   "metadata": {},
   "source": [
    "As we can see, the prediction accuracies are near a random prediction, which would be 50% in this case.\n",
    "\n",
    "To improve the prediction accuracies, we need to finetune the model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "09170955-4acd-4015-a015-2ca550224c0e",
   "metadata": {},
   "source": [
    "Classification accuracy is not a differentiable function, so we use cross entropy loss as a proxy to maximize accuracy.\n",
    "\n",
    "This is the same cross entropy loss discussed earlier.\n",
    "\n",
    "Accordingly, the calc_loss_batch function remains the same as in earlier, with one adjustment: we focus on optimizing only the last token, model(input_batch)[:, -1, :], rather than all tokens, model(input_batch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "019a28d2-fb41-4035-a6a9-e46b651cebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c0723d1-bf12-4de0-9b3f-240b8832bd9e",
   "metadata": {},
   "source": [
    "We use the calc_loss_batch function to compute the loss for a single batch obtained from the previously defined data loaders. To calculate the loss for all batches in a data loader, we define the calc_loss_loader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfa01b06-d0fa-448b-9bc8-82b6cc22f71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55d2cab7-33d1-431d-b2bb-a5242ed352ce",
   "metadata": {},
   "source": [
    "Similar to calculating the training accuracy, we now compute the initial loss for each data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc84920d-7ae0-44ed-9e57-cad863314fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a73c330-7234-46be-b7b9-caa55cceeb71",
   "metadata": {},
   "source": [
    "In the next section, we will implement a training function to finetune the model, which means adjusting the model to minimize the training set loss.\n",
    "\n",
    "Minimizing the training set loss will help increase the classification accuracy, our overall goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9776bd9-7f0c-4c91-92d3-801f5fcc9ac1",
   "metadata": {},
   "source": [
    "# Stage 3: Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e7f8d-cabe-49a8-9b42-24525bc09356",
   "metadata": {},
   "source": [
    "## FINETUNING THE MODEL ON SUPERVISED DATA"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f622efb9-17fd-4b05-99da-44d05b647b52",
   "metadata": {},
   "source": [
    "In this section, we define and use the training function to finetune the pretrained LLM and improve its spam classification accuracy.\n",
    "\n",
    "The training loop is the same overall training loop we used earlier, with the only difference being that we calculate the classification accuracy instead of generating a sample text for evaluating the model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "10c1d7c1-ecde-48b8-b051-eaf4f7c9d8dc",
   "metadata": {},
   "source": [
    "The training function also closely mirrors the train_model_simple function used for pretraining the model earlier.\n",
    "\n",
    "The only two distinctions are that we now track the number of training examples seen (examples_seen) instead of the number of tokens, and we calculate the accuracy after each epoch instead of printing a sample text:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b801ee2-b0bb-4051-84dd-11aff3121b88",
   "metadata": {},
   "source": [
    "Step 1: Set model to training mode\n",
    "\n",
    "Step 2: Reset loss gradients from previous batch iteration\n",
    "\n",
    "Step 3: Calculate loss gradients\n",
    "\n",
    "Step 4: Update model weights using loss gradients\n",
    "\n",
    "Step 5: New: track examples instead of tokens\n",
    "\n",
    "Step 6: Optional evaluation step\n",
    "\n",
    "Step 7: Calculate accuracy after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb070af5-0abf-4307-b26b-3326f916ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens \n",
    "            global_step += 1\n",
    "\n",
    "            ## 130 batches: training, eval_Freq = 50 --> after 50 batches are processed in each epoch, we print train loss and val loss\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "raw",
   "id": "629f774a-4ff5-42ff-90af-c65bf72d1029",
   "metadata": {},
   "source": [
    "The evaluate_model function used in the train_classifier_simple is the same as the one we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9666f84e-d9a6-4eef-84e0-7710576a7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "479ea3d6-18a7-4a5c-a86f-77805f8cdb5a",
   "metadata": {},
   "source": [
    "Next, we initialize the optimizer, set the number of training epochs, and initiate the training using the train_classifier_simple function.\n",
    "\n",
    "We will discuss the choice of the the number of training epochs after we evaluated the results.\n",
    "\n",
    "The training takes about 6 minutes on an M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9decc481-ee70-4114-96aa-df7e46df33c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
      "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
      "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
      "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
      "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
      "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
      "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 3.91 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb35cf1c-eb17-458e-86e7-9130395b0172",
   "metadata": {},
   "source": [
    "We then use matplotlib to plot the loss function for the training and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58f37626-aba7-4fda-bfa8-e8c099a4eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3b0e96c-00a3-46c7-8aae-cf19241e5ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABXiklEQVR4nO3deVxU9f748dfMwAz7viOCyuIK7uZOSaKVZavX6y0ty2+FlZltt1KzX9FiNyvLym5y61a2at1yCfd9FwUX3AGVzYVVGGDm/P4YGB3FBQRmwPfz8TgP5nzO55zznk/km/M5n3M+KkVRFIQQQghhk9TWDkAIIYQQlyeJWgghhLBhkqiFEEIIGyaJWgghhLBhkqiFEEIIGyaJWgghhLBhkqiFEEIIGyaJWgghhLBhkqiFEEIIGyaJWghxTWJjY5k0aZK1wxDihiOJWogmMm7cOFQq1SXLsGHDrB2aEMKG2Vk7ACFuJMOGDWPevHkWZTqdzkrRCCGaA7miFqIJ6XQ6AgICLBZPT08AVq1ahVarZe3ateb67777Ln5+fuTm5gKwZMkSBgwYgIeHB97e3txxxx0cPnzYXP/YsWOoVCp+/PFHBg4ciKOjI7169eLAgQNs3bqVnj174uLiwvDhw8nPzzfvN27cOEaOHMnrr7+Or68vbm5uPP7441RUVFz2u+j1eqZMmUJwcDDOzs706dOHVatWmbdnZGQwYsQIPD09cXZ2plOnTixatOiyx/v000+JiIjAwcEBf39/7rvvPvM2o9FIYmIibdq0wdHRkZiYGH7++WeL/dPS0hg+fDguLi74+/vz4IMPcurUKfP22NhYnn76aV544QW8vLwICAhg+vTpl41HCFshiVoIG1FzD/jBBx+ksLCQnTt38tprr/Hll1/i7+8PQGlpKZMnT2bbtm0sX74ctVrN3XffjdFotDjWtGnTePXVV9mxYwd2dnb8/e9/54UXXuDDDz9k7dq1HDp0iKlTp1rss3z5cvbt28eqVav4/vvv+fXXX3n99dcvG+/EiRPZuHEj8+fPZ/fu3dx///0MGzaMgwcPApCQkIBer2fNmjWkpqbyzjvv4OLiUuuxtm3bxtNPP82MGTNIT09nyZIlDBo0yLw9MTGRr7/+ms8++4w9e/bw7LPP8o9//IPVq1cDUFBQwC233EK3bt3Ytm0bS5YsITc3lwceeMDiPP/5z39wdnZm8+bNvPvuu8yYMYPk5ORr/C8khJUoQogmMXbsWEWj0SjOzs4Wy5tvvmmuo9frla5duyoPPPCA0rFjR+Wxxx674jHz8/MVQElNTVUURVGOHj2qAMqXX35prvP9998rgLJ8+XJzWWJiohIVFWURm5eXl1JaWmoumzNnjuLi4qIYDAZFURRl8ODByjPPPKMoiqJkZGQoGo1GOXHihEU8Q4YMUV5++WVFURSlS5cuyvTp06+pbX755RfFzc1NKSoqumRbeXm54uTkpGzYsMGifPz48cro0aMVRVGUN954Qxk6dKjF9qysLAVQ0tPTzfEPGDDAok6vXr2UF1988ZpiFMJa5B61EE3o5ptvZs6cORZlXl5e5s9arZZvv/2W6OhoQkND+eCDDyzqHjx4kKlTp7J582ZOnTplvpLOzMykc+fO5nrR0dHmzzVX4126dLEoy8vLszh2TEwMTk5O5vW+fftSUlJCVlYWoaGhFnVTU1MxGAxERkZalOv1ery9vQF4+umneeKJJ/jrr7+Ii4vj3nvvtYjrQrfeeiuhoaG0bduWYcOGMWzYMO6++26cnJw4dOgQ586d49Zbb7XYp6Kigm7dugGwa9cuVq5cWesV++HDh81xXnz+wMDAS9pBCFsjiVqIJuTs7Ex4ePgV62zYsAGAM2fOcObMGZydnc3bRowYQWhoKHPnziUoKAij0Ujnzp0vuZdsb29v/qxSqWotu7i7vC5KSkrQaDRs374djUZjsa0mWT766KPEx8fz559/8tdff5GYmMj777/PU089dcnxXF1d2bFjB6tWreKvv/5i6tSpTJ8+na1bt1JSUgLAn3/+SXBwsMV+NQPxSkpKGDFiBO+8884lxw4MDDR/vrAN4PrbQYimIIlaCBty+PBhnn32WebOncsPP/zA2LFjWbZsGWq1mtOnT5Oens7cuXMZOHAgAOvWrWuwc+/atYuysjIcHR0B2LRpEy4uLoSEhFxSt1u3bhgMBvLy8syx1CYkJITHH3+cxx9/nJdffpm5c+fWmqgB7OzsiIuLIy4ujmnTpuHh4cGKFSu49dZb0el0ZGZmMnjw4Fr37d69O7/88gthYWHY2ck/a6Jlkd9oIZqQXq8nJyfHoszOzg4fHx8MBgP/+Mc/iI+P5+GHH2bYsGF06dKF999/n+effx5PT0+8vb354osvCAwMJDMzk5deeqnBYquoqGD8+PG8+uqrHDt2jGnTpjFx4kTU6kvHnEZGRjJmzBgeeugh3n//fbp160Z+fj7Lly8nOjqa22+/nUmTJjF8+HAiIyM5e/YsK1eupEOHDrWe+48//uDIkSMMGjQIT09PFi1ahNFoJCoqCldXV6ZMmcKzzz6L0WhkwIABFBYWsn79etzc3Bg7diwJCQnMnTuX0aNHm0d1Hzp0iPnz5/Pll19ectUvRHMiiVqIJrRkyRKLrliAqKgo9u/fz5tvvklGRgZ//PEHYOqy/eKLLxg9ejRDhw4lJiaG+fPn8/TTT9O5c2eioqL46KOPiI2NbZDYhgwZQkREBIMGDUKv1zN69OgrPr40b948/t//+38899xznDhxAh8fH2666SbuuOMOAAwGAwkJCRw/fhw3NzeGDRt2yT33Gh4eHvz6669Mnz6d8vJyIiIi+P777+nUqRMAb7zxBr6+viQmJnLkyBE8PDzo3r07//znPwEICgpi/fr1vPjiiwwdOhS9Xk9oaCjDhg2r9Q8NIZoTlaIoirWDEEJY17hx4ygoKGDhwoXWDkUIcRH5U1MIIYSwYZKohRBCCBsmXd9CCCGEDZMraiGEEMKGSaIWQgghbJgkaiGEEMKGSaK+Dp988glhYWE4ODjQp08ftmzZYu2QGs2aNWsYMWIEQUFBqFSqSx7jURSFqVOnEhgYiKOjI3FxceZZlGqcOXOGMWPG4ObmhoeHB+PHjze/HrLG7t27GThwIA4ODoSEhPDuu+829ldrEImJifTq1QtXV1f8/PwYOXIk6enpFnXKy8tJSEjA29sbFxcX7r33XvP0lTUyMzO5/fbbcXJyws/Pj+eff56qqiqLOqtWraJ79+7odDrCw8NJSkpq7K/XIObMmUN0dDRubm64ubnRt29fFi9ebN5+o7dPbd5++21UKhWTJk0yl0k7wfTp01GpVBZL+/btzdtbXBtZdUqQZmz+/PmKVqtVvvrqK2XPnj3KY489pnh4eCi5ubnWDq1RLFq0SHnllVeUX3/9VQGUBQsWWGx/++23FXd3d2XhwoXKrl27lDvvvFNp06aNUlZWZq4zbNgwJSYmRtm0aZOydu1aJTw83Dz7kaIoSmFhoeLv76+MGTNGSUtLU77//nvF0dFR+fzzz5vqa9ZbfHy8Mm/ePCUtLU1JSUlRbrvtNqV169ZKSUmJuc7jjz+uhISEKMuXL1e2bdum3HTTTUq/fv3M26uqqpTOnTsrcXFxys6dO5VFixYpPj4+5tmoFEVRjhw5ojg5OSmTJ09W9u7dq3z88ceKRqNRlixZ0qTftz5+//135c8//1QOHDigpKenK//85z8Ve3t7JS0tTVEUaZ+LbdmyRQkLC1Oio6PNs5YpirSToijKtGnTlE6dOinZ2dnmJT8/37y9pbWRJOp66t27t5KQkGBeNxgMSlBQkJKYmGjFqJrGxYnaaDQqAQEBynvvvWcuKygoUHQ6nfL9998riqIoe/fuVQBl69at5jqLFy9WVCqVearETz/9VPH09FT0er25zosvvmgxHWNzkZeXpwDK6tWrFUUxtYe9vb3y008/mevs27dPAZSNGzcqimL6Y0itVis5OTnmOnPmzFHc3NzMbfLCCy8onTp1sjjXqFGjlPj4+Mb+So3C09NT+fLLL6V9LlJcXKxEREQoycnJFtOLSjuZTJs2TYmJial1W0tsI+n6roeKigq2b99OXFycuUytVhMXF8fGjRutGJl1HD16lJycHIv2cHd3p0+fPub22LhxIx4eHvTs2dNcJy4uDrVazebNm811Bg0ahFarNdeJj48nPT2ds2fPNtG3aRiFhYXA+Skst2/fTmVlpUUbtW/fntatW1u0UZcuXczTUoLp+xcVFbFnzx5znQuPUVOnuf3eGQwG5s+fT2lpKX379pX2uUhCQgK33377Jd9F2um8gwcPEhQURNu2bRkzZgyZmZlAy2wjSdT1cOrUKQwGg8V/ZDDN8XvxhAs3gprvfKX2yMnJwc/Pz2K7nZ0dXl5eFnVqO8aF52gOjEYjkyZNon///uY5onNyctBqtXh4eFjUvbiNrvb9L1enqKiIsrKyxvg6DSo1NRUXFxd0Oh2PP/44CxYsoGPHjtI+F5g/fz47duwgMTHxkm3STiZ9+vQhKSmJJUuWMGfOHI4ePcrAgQMpLi5ukW0kk3II0cASEhJIS0tr0CkoW4qoqChSUlIoLCzk559/ZuzYsaxevdraYdmMrKwsnnnmGZKTk3FwcLB2ODZr+PDh5s/R0dH06dOH0NBQfvzxR/M0rS2JXFHXg4+PDxqN5pJRhLm5uQQEBFgpKuup+c5Xao+AgADy8vIstldVVXHmzBmLOrUd48Jz2LqJEyfyxx9/sHLlSlq1amUuDwgIoKKigoKCAov6F7fR1b7/5eq4ubk1i3+gtFot4eHh9OjRg8TERGJiYvjwww+lfapt376dvLw8unfvjp2dHXZ2dqxevZqPPvoIOzs7/P39pZ1q4eHhQWRkJIcOHWqRv0uSqOtBq9XSo0cPli9fbi4zGo0sX76cvn37WjEy62jTpg0BAQEW7VFUVMTmzZvN7dG3b18KCgrYvn27uc6KFSswGo306dPHXGfNmjVUVlaa6yQnJxMVFYWnp2cTfZv6URSFiRMnsmDBAlasWEGbNm0stvfo0QN7e3uLNkpPTyczM9OijVJTUy3+oElOTsbNzY2OHTua61x4jJo6zfX3zmg0otfrpX2qDRkyhNTUVFJSUsxLz549GTNmjPmztNOlSkpKOHz4MIGBgS3zd6nJh6+1EPPnz1d0Op2SlJSk7N27V5kwYYLi4eFhMYqwJSkuLlZ27typ7Ny5UwGUf/3rX8rOnTuVjIwMRVFMj2d5eHgov/32m7J7927lrrvuqvXxrG7duimbN29W1q1bp0RERFg8nlVQUKD4+/srDz74oJKWlqbMnz9fcXJyahaPZz3xxBOKu7u7smrVKotHRs6dO2eu8/jjjyutW7dWVqxYoWzbtk3p27ev0rdvX/P2mkdGhg4dqqSkpChLlixRfH19a31k5Pnnn1f27dunfPLJJ83msZqXXnpJWb16tXL06FFl9+7dyksvvaSoVCrlr7/+UhRF2udyLhz1rSjSToqiKM8995yyatUq5ejRo8r69euVuLg4xcfHR8nLy1MUpeW1kSTq6/Dxxx8rrVu3VrRardK7d29l06ZN1g6p0axcuVIBLlnGjh2rKIrpEa3XXntN8ff3V3Q6nTJkyBAlPT3d4hinT59WRo8erbi4uChubm7Kww8/rBQXF1vU2bVrlzJgwABFp9MpwcHByttvv91UX/G61NY2gDJv3jxznbKyMuXJJ59UPD09FScnJ+Xuu+9WsrOzLY5z7NgxZfjw4Yqjo6Pi4+OjPPfcc0plZaVFnZUrVypdu3ZVtFqt0rZtW4tz2LJHHnlECQ0NVbRareLr66sMGTLEnKQVRdrnci5O1NJOpsekAgMDFa1WqwQHByujRo1SDh06ZN7e0tpIZs8SQgghbJjcoxZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwoZJor4Oer2e6dOno9frrR2KTZN2ujppo6uTNro6aaOra45tZNXnqBMTE/n111/Zv38/jo6O9OvXj3feeYeoqKjL7pOUlMTDDz9sUabT6SgvL2/scC9RVFSEu7s7hYWFuLm5Nfn5mwtpp6uTNro6aaOrkza6uubYRla9ol69ejUJCQls2rSJ5ORkKisrGTp0KKWlpVfcz83NjezsbPOSkZHRRBELIYQQTcuq01wuWbLEYj0pKQk/Pz+2b9/OoEGDLrufSqVqNrMpCSGEENfDpuajLiwsBMDLy+uK9UpKSggNDcVoNNK9e3feeustOnXqdE3nqKqqYufOnfj7+6NWX1+HQnFxMQAnTpygqKjouo7Vkkk7XZ200dVJG12dtNHV2UobGY1GcnNz6datG3Z2V07FNvOub6PRyJ133klBQQHr1q27bL2NGzdy8OBBoqOjKSwsZObMmaxZs4Y9e/ZYzP9bQ6/XWwwa2L59O7fcckujfAchhBCiLrZs2UKvXr2uWMdmEvUTTzzB4sWLWbduXa0J93IqKyvp0KEDo0eP5o033rhk+/Tp03n99dcvKd+yZQuBgYHXFbMQQghRH9nZ2fTu3ZuMjAxat259xbo2kagnTpzIb7/9xpo1a2jTpk2d97///vuxs7Pj+++/v2TbxVfUJ06coGPHjmRlZdXpDwIhhBCioRw/fpyQkJBrykVWHfWtKAoTJ05kwYIFrFixol5J2mAwkJqaetmrY51Oh5ubm3lxdXW93rCFEEKIJmPVwWQJCQl89913/Pbbb7i6upKTkwOAu7s7jo6OADz00EMEBweTmJgIwIwZM7jpppsIDw+noKCA9957j4yMDB599FGrfQ8hhBCisVg1Uc+ZMweA2NhYi/J58+Yxbtw4ADIzMy1GZ589e5bHHnuMnJwcPD096dGjBxs2bKBjx45NFbYQQgjRZGziHnVTqst9ASHEjcdgMFBZWWntMEQzZ29vj0ajuez2uuQim3qOWgghrEVRFHJycigoKLB2KKKF8PDwICAgAJVKdV3HkUR9PcoKIHMTuLeCgM7WjkYIcR1qkrSfnx9OTk7X/Y+ruHEpisK5c+fIy8sDuO5HgSVRX48V/w+2zoU+j8Pwd6wdjRCingwGgzlJe3t7Wzsc0QLUDIjOy8vDz8/vit3gVyPTXF6PsP6mn8fWWzcOIcR1qbkn7eTkZOVIREtS8/t0vWMeJFFfj9DqRJ2bBufOWDcWIcR1k+5u0ZAa6vdJEvX1cPEDn0hAgcyN1o5GCCFECySJ+nqFDTD9lO5vIUQLERYWxqxZs665/qpVq1CpVI0+Yj4pKQkPD49GPYctkkR9vWq6v4+ttW4cQogbjkqluuIyffr0eh1369atTJgw4Zrr9+vXj+zsbNzd3et1PnFlMur7etVcUeekmh7XcvSwZjRCiBtIdna2+fMPP/zA1KlTSU9PN5e5uLiYPyuKgsFguOrcxwC+vr51ikOr1RIQEFCnfcS1kyvq6+UaAN7hmO5Tb7J2NEKIG0hAQIB5cXd3R6VSmdf379+Pq6srixcvpkePHuh0OtatW8fhw4e566678Pf3x8XFhV69erFs2TKL417c9a1Sqfjyyy+5++67cXJyIiIigt9//928/eKu75ou6qVLl9KhQwdcXFwYNmyYxR8WVVVVPP3003h4eODt7c2LL77I2LFjGTlyZJ3aYM6cObRr1w6tVktUVBTffPONeZuiKEyfPp3WrVuj0+kICgri6aefNm//9NNPiYiIwMHBAX9/f+677746nbupSKJuCNL9LUSLoygK5yqqrLI05JudX3rpJd5++2327dtHdHQ0JSUl3HbbbSxfvpydO3cybNgwRowYQWZm5hWP8/rrr/PAAw+we/dubrvtNsaMGcOZM5d/2uXcuXPMnDmTb775hjVr1pCZmcmUKVPM29955x2+/fZb5s2bx/r16ykqKmLhwoV1+m4LFizgmWee4bnnniMtLY3/+7//4+GHH2blypUA/PLLL3zwwQd8/vnnHDx4kIULF9KlSxcAtm3bxtNPP82MGTNIT09nyZIlDBo0qE7nbyrS9d0QwgbAjv9AhgwoE6KlKKs00HHqUquce++MeJy0DfPP84wZM7j11lvN615eXsTExJjX33jjDRYsWMDvv//OxIkTL3uccePGMXr0aADeeustPvroI7Zs2cKwYcNqrV9ZWclnn31Gu3btAJg4cSIzZswwb//44495+eWXufvuuwGYPXs2ixYtqtN3mzlzJuPGjePJJ58EYPLkyWzatImZM2dy8803k5mZSUBAAHFxcdjb29O6dWt69+4NmCZ8cnZ25o477sDV1ZXQ0FC6detWp/M3Fbmibgg1V9TZu6C80LqxCCHEBXr27GmxXlJSwpQpU+jQoQMeHh64uLiwb9++q15RR0dHmz87Ozvj5uZmfkVmbZycnMxJGkyv0aypX1hYSG5urjlpAmg0Gnr06FGn77Zv3z769+9vUda/f3/27dsHwP33309ZWRlt27blscceY8GCBVRVVQFw6623EhoaStu2bXnwwQf59ttvOXfuXJ3O31TkirohuAeDZxs4exQyN0PkUGtHJIS4To72GvbOiLfauRuKs7OzxfqUKVNITk5m5syZhIeH4+joyH333UdFRcUVj2Nvb2+xrlKpMBqNdarf1JM1hoSEkJ6ezrJly0hOTubJJ5/kvffeY/Xq1bi6urJjxw5WrVrFX3/9xdSpU5k+fTpbt261uUfA5Iq6oUTdBpHDQOt89bpCCJunUqlw0tpZZWnMN6StX7+ecePGcffdd9OlSxcCAgI4duxYo52vNu7u7vj7+7N161ZzmcFgYMeOHXU6TocOHVi/3vKW4/r16+nYsaN53dHRkREjRvDRRx+xatUqNm7cSGpqKgB2dnbExcXx7rvvsnv3bo4dO8aKFSuu45s1DrmibijD3rJ2BEIIcVURERH8+uuvjBgxApVKxWuvvXbFK+PG8tRTT5GYmEh4eDjt27fn448/5uzZs3X6I+X555/ngQceoFu3bsTFxfG///2PX3/91TyKPSkpCYPBQJ8+fXBycuK///0vjo6OhIaG8scff3DkyBEGDRqEp6cnixYtwmg0EhUV1Vhfud4kUQshxA3kX//6F4888gj9+vXDx8eHF198kaKioiaP48UXXyQnJ4eHHnoIjUbDhAkTiI+Pr9MsUyNHjuTDDz9k5syZPPPMM7Rp04Z58+YRGxsLmOaDfvvtt5k8eTIGg4EuXbrwv//9D29vbzw8PPj111+ZPn065eXlRERE8P3339OpU6dG+sb1p1Ka+qaBlR0/fpyQkBCysrJo1arVdR+vymBEo1ad/yuwIAvUduB2ffOPCiGaTnl5OUePHqVNmzY4ODhYO5wbktFopEOHDjzwwAO88cYb1g6nQVzp96ouuUjuUV+HF37eRfc3kkk7Uf3X6JJ/wqzOsOUL6wYmhBA2LiMjg7lz53LgwAFSU1N54oknOHr0KH//+9+tHZrNkUR9Hc6eq6SovIrVB6ofUfDvBCoNnDtt3cCEEMLGqdVqkpKS6NWrF/379yc1NZVly5bRoUMHa4dmc+Qe9XUYHOlL8t5cVh/IZ+ItEdBpJHS8E3Su1g5NCCFsWkhIyCUjtkXtJFFfh8GRphfX78gsoLCsEndHeTRLCCFEw5Ku7+sQ4uVEO19nDEaF9YdOWW60wuMOQgghWh5J1NdpcKQfAKvT800FJ7bD3Fvg6zutGJUQQoiWQhL1dRocZer+Xn0g3/R6PAcPU7LO2gyVZdYNTgghRLMnifo69Wnjhc5OTU5ROem5xeDVFlwDwVABx7de/QBCCCHEFVg1UScmJtKrVy9cXV3x8/Nj5MiRpKenX3W/n376ifbt2+Pg4ECXLl3qPDVaQ3Kw19C3nTdQ3f2tUpmmvQQ4JiMahRBCXB+rJurVq1eTkJDApk2bSE5OprKykqFDh1JaWnrZfTZs2MDo0aMZP348O3fuZOTIkYwcOZK0tLQmjNxSzejv1Qeq71PXTHt5bJ2VIhJCiGsXGxvLpEmTzOthYWHMmjXrivuoVCoWLlx43eduqONcyfTp0+natWujnqMxWTVRL1myhHHjxtGpUydiYmJISkoiMzOT7du3X3afDz/8kGHDhvH888/ToUMH3njjDbp3787s2bObMHJLNYl667EzlOqrzl9RH98KleVWi0sI0bKNGDGCYcOG1bpt7dq1qFQqdu/eXefjbt26lQkTJlxveBYulyyzs7MZPnx4g56rpbGpe9SFhYUAeHl5XbbOxo0biYuLsyiLj49n48aNtdbX6/UUFRWZl+Li4oYLuFobH2daezlRaVDYcPg0eIeDiz8Y9KaBZUII0QjGjx9PcnIyx48fv2TbvHnz6NmzJ9HR0XU+rq+vL05OTg0R4lUFBASg0+ma5FzNlc0kaqPRyKRJk+jfvz+dO3e+bL2cnBz8/f0tyvz9/cnJyam1fmJiIu7u7ublwnlKG4pKpbqg+zvPdJ9aur+FEI3sjjvuwNfXl6SkJIvykpISfvrpJ8aPH8/p06cZPXo0wcHBODk50aVLF77//vsrHvfiru+DBw8yaNAgHBwc6NixI8nJyZfs8+KLLxIZGYmTkxNt27bltddeo7KyEjBNN/n666+za9cuVCrTJEY1MV/c9Z2amsott9yCo6Mj3t7eTJgwgZKSEvP2cePGMXLkSGbOnElgYCDe3t4kJCSYz3UtjEYjM2bMoFWrVuh0Orp27cqSJUvM2ysqKpg4cSKBgYE4ODgQGhpKYmIiAIqiMH36dFq3bo1OpyMoKIinn376ms9dHzaTqBMSEkhLS2P+/PkNetyXX36ZwsJC87J3794GPX6NmkS9Kr36Ma2w6kSdIYlaiGatorTui6Hq/P6GKlPZxY9rXm7fOrCzs+Ohhx4iKSmJCydC/OmnnzAYDIwePZry8nJ69OjBn3/+SVpaGhMmTODBBx9ky5Yt13QOo9HIPffcg1arZfPmzXz22We8+OKLl9RzdXUlKSmJvXv38uGHHzJ37lw++OADAEaNGsVzzz1Hp06dyM7OJjs7m1GjRl1yjNLSUuLj4/H09GTr1q389NNPLFu2jIkTJ1rUW7lyJYcPH2blypX85z//ISkp6ZI/Vq7kww8/5P3332fmzJns3r2b+Ph47rzzTg4ePAjARx99xO+//86PP/5Ieno63377LWFhYQD88ssvfPDBB3z++eccPHiQhQsX0qVLl2s+d33YxCtEJ06cyB9//MGaNWuuOt1XQEAAubm5FmW5ubkEBATUWl+n01l0qzTWvKt923mj1ag5fraMI6dKaRdafZ86aytU6cFOunaEaJbeCqr7PvcnQae7TZ/3/w9+GgehA+DhP8/XmdWl9gl8phfW6VSPPPII7733HqtXrzbPwzxv3jzuvfdec0/ilClTzPWfeuopli5dyo8//kjv3r2vevxly5axf/9+li5dSlCQqS3eeuutS+4rv/rqq+bPYWFhTJkyhfnz5/PCCy/g6OiIi4sLdnZ2l/23GuC7776jvLycr7/+Gmdn0yuZZ8+ezYgRI3jnnXfMvamenp7Mnj0bjUZD+/btuf3221m+fDmPPfbYNbXZzJkzefHFF/nb3/4GwDvvvMPKlSuZNWsWn3zyCZmZmURERDBgwABUKhWhoaHmfTMzMwkICCAuLg57e3tat259Te14Pax6Ra0oChMnTmTBggWsWLGCNm3aXHWfvn37snz5couy5ORk+vbt21hhXhNnnR292ngC1Y9p+UaBkw9UlcGJHVaNTQjRcrVv355+/frx1VdfAXDo0CHWrl3L+PHjATAYDLzxxht06dIFLy8vXFxcWLp0KZmZmdd0/H379hESEmJO0kCt/97+8MMP9O/fn4CAAFxcXHj11Vev+RwXnismJsacpAH69++P0Wi0eHS3U6dOaDQa83pgYCB5eXnXdI6ioiJOnjxJ//79Lcr79+/Pvn37AFP3ekpKClFRUTz99NP89ddf5nr3338/ZWVltG3blscee4wFCxZQVVVFY7LqFXVCQgLfffcdv/32G66urub7zO7u7jg6OgLw0EMPERwcbL4/8MwzzzB48GDef/99br/9dubPn8+2bdv44gvrzwE9ONKX9YdOs/pAPo8MaGPq/t77m6n7O9S6f0gIIerpnyfrvo/mgh609iNMx1BddF00KfX64rrA+PHjeeqpp/jkk0+YN28e7dq1Y/DgwQC89957fPjhh8yaNYsuXbrg7OzMpEmTqKioaLDzb9y4kTFjxvD6668THx+Pu7s78+fP5/3332+wc1zI3t7eYl2lUmFswPkVunfvztGjR1m8eDHLli3jgQceIC4ujp9//pmQkBDS09NZtmwZycnJPPnkk+YejYvjaihWvaKeM2cOhYWFxMbGEhgYaF5++OEHc53MzEyys7PN6/369eO7777jiy++ICYmhp9//pmFCxdecQBaU4mNMr33e9OR05RXGkxdXWDq/hZCNE9a57ovmguugTR2pjJ7x2s7bj088MADqNVqvvvuO77++mseeeQRVCoVAOvXr+euu+7iH//4BzExMbRt25YDBw5c87E7dOhAVlaWxb/DmzZtsqizYcMGQkNDeeWVV+jZsycRERFkZGRYfl2tFoPBcNVz7dq1y+JdGuvXr0etVhMVFXXNMV+Jm5sbQUFBl0yxuX79eovBxm5ubowaNYq5c+fyww8/8Msvv3DmzBkAHB0dGTFiBB999BGrVq1i48aNpKY23B9eF7PqFfWFgx8uZ9WqVZeU3X///dx///2NENH1ifBzIdDdgezCcjYdOU1sx7sguAcExlg7NCFEC+bi4sKoUaN4+eWXKSoqYty4ceZtERER/Pzzz2zYsAFPT0/+9a9/kZube81PwMTFxREZGcnYsWN57733KCoq4pVXXrGoExERQWZmJvPnz6dXr178+eefLFiwwKJOWFgYR48eJSUlhVatWuHq6nrJY1ljxoxh2rRpjB07lunTp5Ofn89TTz3Fgw8+eMnTPtfj+eefZ9q0abRr146uXbsyb948UlJS+PbbbwH417/+RWBgIN26dUOtVvPTTz8REBCAh4cHSUlJGAwG+vTpg5OTE//9739xdHS0uI/d0Gxm1HdLYPmYVj64+kOrHpZ/XQshRCMYP348Z8+eJT4+3uJ+8quvvkr37t2Jj48nNjaWgIAARo4cec3HVavVLFiwgLKyMnr37s2jjz7Km2++aVHnzjvv5Nlnn2XixIl07dqVDRs28Nprr1nUuffeexk2bBg333wzvr6+tT4i5uTkxNKlSzlz5gy9evXivvvuY8iQIQ3+Qqunn36ayZMn89xzz9GlSxeWLFnC77//TkREBGAawf7uu+/Ss2dPevXqxbFjx1i0aBFqtRoPDw/mzp1L//79iY6OZtmyZfzvf//D29u7QWO8kEq5lsvaFuT48eOEhISQlZV11RHm9bE4NZsnvt1BW19nVjwX2+DHF0I0vPLyco4ePUqbNm1wcHCwdjiihbjS71VdcpFc6jWw/hE+aNQqjuSXknXmHCGG47DxY1BpYMQsa4cnhBCimZGu7wbm5mBPj9amx7RWHcg3vUZ0x9eQ+pPlSxCEEEKIayCJuhEMjqq+T52eD36dYMBkuO8r4Ia6yyCEEKIBSKJuBDUDyjYcPoXeqEDcNIiMB03jPGMnhBCi5ZJE3Qg6Brrh46LjXIWB7cfOWjscIYQQzZgk6kagVqsYFOkDVD+mZTTAoeWw4k3TZyGETWrIt1sJ0VC/TzLqu5HERvnx644TrD6Qz8vDIuGnh0FfCO1vg6Bu1g5PCHEBrVaLWq3m5MmT+Pr6otVqzW/2EqKuFEWhoqKC/Px81Go1Wq32uo4nibqRDAz3QaWC/TnFZBdXEBjaFw4sgWPrJVELYWPUajVt2rQhOzubkyfr8W5vIWrh5ORE69atUauvr/NaEnUj8XTWEtPKg5SsAtYcyGdUaP/qRL0O+k28+gGEEE1Kq9XSunVrqqqqrvpOaiGuRqPRYGdn1yA9M5KoG9HgSF9SsgpYfSCfUbHVU6plbjDdp1ZrrryzEKLJqVQq7O3tG20WJCHqQwaTNaLY6uep1x48RZVfF9C6Qnkh5O6xcmRCCCGaC0nUjSi6lQceTvYUl1ex80QJtL7JtOHYOusGJoQQotmQRN2INGoVAyMueEtZWHX3d8b6K+wlhBBCnCeJupHFVr+lbNWBPAgdYCrMWA/yvKYQQohrIIm6kQ2sfvFJ2oki8l07gL0zlJ2FvL1WjkwIIURzIIm6kfm5OtApyA2AtUcKoHUf0wbp/hZCCHENJFE3gZrR36sP5ENo9X1qGVAmhBDiGkiibgKDI/0AWHMgH8OF96kVmfZSCCHElckLT5pAt9YeuOrsOHuukjSlLTER8aYu8Co92DtYOzwhhBA2TBJ1E7DXqBkQ4cPitBxWHSokZsyP1g5JCCFEMyFd301k8IWPaQkhhBDXSBJ1ExlUnah3ZRVwtrQCinNhz0K5Ty2EEOKKJFE3kSAPRyL9XTAqsP7ASfgwGn4aC6cPWTs0IYQQNsyqiXrNmjWMGDGCoKAgVCoVCxcuvGL9VatWoVKpLllycnKaJuDrFBtlGv296lAhhPSBgGg4d8bKUQkhhLBlVk3UpaWlxMTE8Mknn9Rpv/T0dLKzs82Ln59fI0XYsGruU68+kI9xzC/w+NrzL0ARQgghamHVUd/Dhw9n+PDhdd7Pz88PDw+Phg+okfUM88RJqyG/WM++vHN0CnK3dkhCCCFsXLO8R921a1cCAwO59dZbWb+++byKU2enoV87b6D6LWUAlWVQcc6KUQkhhLBlzSpRBwYG8tlnn/HLL7/wyy+/EBISQmxsLDt27LjsPnq9nqKiIvNSXFzchBFfyvyYVno+LHoB3m4NqT9ZNSYhhBC2q1m98CQqKoqoqCjzer9+/Th8+DAffPAB33zzTa37JCYm8vrrrzdViFdlep3oHnZknEXfxgWdocL0OtEeY60dmhBCCBvUrK6oa9O7d28OHbr8I04vv/wyhYWF5mXvXutOL9na24m2Ps5UGRV2abqYCo+tk+ephRBC1KrZJ+qUlBQCAwMvu12n0+Hm5mZeXF1dmzC62tW8/OSPs61AbQ9FJ+DsMesGJYQQwiZZNVGXlJSQkpJCSkoKAEePHiUlJYXMzEzAdDX80EMPmevPmjWL3377jUOHDpGWlsakSZNYsWIFCQkJ1gi/3gZXT3u57GARSnB3U6FMeymEEKIWVr1HvW3bNm6++Wbz+uTJkwEYO3YsSUlJZGdnm5M2QEVFBc899xwnTpzAycmJ6Oholi1bZnGM5qBvW290dmpOFpZztlNvvLI2m+5Td3/Q2qEJIYSwMSpFubFujh4/fpyQkBCysrJo1aqV1eJ46KstrDmQz5ybChie8iS4t4ZnU60WjxBCiKZTl1zU7O9RN1c1j2n9nBcMKg0UZsLZDCtHJYQQwtZIoraSmkS9NqMMQ1A3U2FG83l5ixBCiKZRr0SdlZXF8ePHzetbtmxh0qRJfPHFFw0WWEvXzteZVp6OVBiMHHerTtTHJFELIYSwVK9E/fe//52VK1cCkJOTw6233sqWLVt45ZVXmDFjRoMG2FKpVCrzVfUaffVLXI6ttWJEQgghbFG9EnVaWhq9e/cG4Mcff6Rz585s2LCBb7/9lqSkpIaMr0WrSdTf5QSZ7lMXZEDh8avsJYQQ4kZSr0RdWVmJTqcDYNmyZdx5550AtG/fnuzs7IaLroXrF+6DvUbFvjOg9+0Cdg6Qn27tsIQQQtiQeiXqTp068dlnn7F27VqSk5MZNmwYACdPnsTb27tBA2zJXHR29Az1AuB/UYnwUiaED7FyVEIIIWxJvRL1O++8w+eff05sbCyjR48mJiYGgN9//93cJS6uTc1byv7MtAM7nZWjEUIIYWvq9Way2NhYTp06RVFREZ6enubyCRMm4OTk1GDB3Qhio3x5e/F+Nh45TXmlAQd7jWmCDpXK2qEJIYSwAfW6oi4rK0Ov15uTdEZGBrNmzSI9PR0/P78GDbCli/J3xd9NR3mlkZOL3oVPboK0X6wdlhBCCBtRr0R911138fXXXwNQUFBAnz59eP/99xk5ciRz5sxp0ABbugsf08o9mQH5+2SCDiGEEGb1StQ7duxg4MCBAPz888/4+/uTkZHB119/zUcffdSgAd4IYqNMvRBfldwED3wDt7xm5YiEEELYinol6nPnzpnndf7rr7+45557UKvV3HTTTWRkyPuq66p/uA8atYrk074cD4wDZxk5L4QQwqReiTo8PJyFCxeSlZXF0qVLGTp0KAB5eXm4ubk1aIA3AndHe7qFeACw5sAp6wYjhBDCptQrUU+dOpUpU6YQFhZG79696du3L2C6uu7WrVuDBnijqLlPvTd1O6x6GzZ/buWIhBBC2IJ6Jer77ruPzMxMtm3bxtKlS83lQ4YM4YMPPmiw4G4kNfepS7JSYVUibPvKyhEJIYSwBfV6jhogICCAgIAA8yxarVq1kpedXIdOQW54O2tZXRoBDkD+fig9Bc4+1g5NCCGEFdXritpoNDJjxgzc3d0JDQ0lNDQUDw8P3njjDYxGY0PHeENQq1UMivTlLG7kObYzFcr81EIIccOrV6J+5ZVXmD17Nm+//TY7d+5k586dvPXWW3z88ce89po8WlRfsdWvE91k7GAqkOephRDihlevru///Oc/fPnll+ZZswCio6MJDg7mySef5M0332ywAG8kA8J9UKlgcXE77tQCx+SKWgghbnT1uqI+c+YM7du3v6S8ffv2nDlz5rqDulF5u+iIDnZni7G6bfP2wDlpTyGEuJHVK1HHxMQwe/bsS8pnz55NdHT0dQd1Ixsc5cdp3MnWhpoKMjZYNyAhhBBWVa+u73fffZfbb7+dZcuWmZ+h3rhxI1lZWSxatKhBA7zRDI705aPlB1lTEcUoMkz3qTvcYe2whBBCWEm9rqgHDx7MgQMHuPvuuykoKKCgoIB77rmHPXv28M033zR0jDeUmFbuuDvas7YiylSQIQPKhBDiRlbv56iDgoIuGTS2a9cu/v3vf/PFF19cd2A3KjuNmgERPmzeXT3yOycNys6Co+eVdxRCCNEi1euKWjSu2Ehf8vHguKYVoEDGRmuHJIQQwkqsmqjXrFnDiBEjCAoKQqVSsXDhwqvus2rVKrp3745OpyM8PJykpKRGj7Op1bz3e01FpKlAXnwihBA3LKsm6tLSUmJiYvjkk0+uqf7Ro0e5/fbbufnmm0lJSWHSpEk8+uijFu8bbwn83BzoEOjG/wx92ReVAJ3vtXZIQgghrKRO96jvueeeK24vKCio08mHDx/O8OHDr7n+Z599Rps2bXj//fcB6NChA+vWreODDz4gPj6+Tue2dbFRvszJ7sQX6mA+CO5q7XCEEEJYSZ2uqN3d3a+4hIaG8tBDDzVWrGzcuJG4uDiLsvj4eDZubHn3cM3d3wfyMRoVK0cjhBDCWup0RT1v3rzGiuOa5OTk4O/vb1Hm7+9PUVERZWVlODo6XrKPXq9Hr9eb14uLixs9zobQI9QTF50dlaVnyNrwI6E+rtD+NmuHJYQQoom1+FHfiYmJFlf9HTt2tHZI18Reo6Z/uDe3qFMIXTYB1s60dkhCCCGsoFkl6oCAAHJzcy3KcnNzcXNzq/VqGuDll1+msLDQvOzdu7cpQm0QgyP92GzsQJYmBIJ7giJd4EIIcaNpVom6b9++LF++3KIsOTnZ/BrT2uh0Otzc3MyLq6trY4fZYAZH+ZKNN4PPvUNh7JugUlk7JCGEEE3Mqom6pKSElJQUUlJSANPjVykpKWRmZgKmq+ELB6c9/vjjHDlyhBdeeIH9+/fz6aef8uOPP/Lss89aI/xGF+zhSISfC0YF1h06Ze1whBBCWIFVE/W2bdvo1q0b3bp1A2Dy5Ml069aNqVOnApCdnW1O2gBt2rThzz//JDk5mZiYGN5//32+/PLLFvdo1oVqRn+v238CclKtHI0QQoimplKUG+vG5/HjxwkJCSErK4tWrVpZO5yrWnswn0n/Tma9wzPo1EZUL2WC1tnaYQkhhLgOdclFzeoe9Y2oV5gX5+y9OKW4oTJWQdZma4ckhBCiCUmitnEO9hr6tvNms7G9qeCYTHsphBA3EknUzcDgSF82Gauf/z4mE3QIIcSNRBJ1MzA40pfNRtP81MqJ7VBxzsoRCSGEaCqSqJuBMB9n1J5hZCteqIyVcHyrtUMSQgjRRCRRNxODo/zYVH1VLfephRDixiGJupkYHHVB93eGJGohhLhRSKJuJm5q680OlWlAmXJ8O1SWWzkiIYQQTUESdTPhpLXDP6wTuYoHaoMeTmyzdkhCCCGagCTqZmRwlJ+5+1vuUwshxI1BEnUzEnvBfWrDUUnUQghxI5BE3Yy083XhiHM3KhQNhXqjzE8thBA3AEnUzYhKpSIsqivR+i/5KOg9mZ9aCCFuAJKom5nBUX6Uo2PNgXxrhyKEEKIJSKJuZvqHe2OnVnHkVClZOaesHY4QQohGJom6mXF1sCe2lYo/tP8kYG4XqKqwdkhCCCEakSTqZqh7h3ACVaexN5yD3DRrhyOEEKIRSaJuhmKj/Pm/imcZbJyD3j/G2uEIIYRoRJKom6EOga5kuMSQUeHOtmNnrR2OEEKIRmRn7QBE3alUKgZH+vLz9uPoV70P61LBvzMEdIaALuDbHux01g5TCCFEA5BE3UzFRpkStWP2ZjBsh2Nrz29U24FP5Pnk7V+dwF38rBewEEKIepFE3UwNCPfBTq1i2rkHiFb3pKM6kx66E0Qox3AyFEHeXtOS+uP5nZz9TIk7+m8QM8p6wQshhLhmkqibKQ8nLR+N7sbCnX6szgrn52I9VAIoBHCGjuoMummP09vpJBHGY3iWZ6EqzYPDK6B1v/MHOpsBP/wDgnvAiFlW+jZCCCEuRxJ1M3Zbl0Bu6xKIoiicLCwnJbOAnZlnScnyYv0JX1aUd4fqaasdKSdKdZwBrtkYj7XF3/4Y3Vp70KFwN/Y5u4GL3hv+XfUVt7n7vAt4tQG1pkm/oxBC3OgkUbcAKpWKYA9Hgj0cuT06EIBKg5H92cWkZJ1lZ1YBKZkFpJxyIKUoHIqAfXsA8Lc7xz3er9LG2RnHXSfp1tqDYFc7VIdXgKECDiw5fyJ7J/DraHnf27c9OHo0+ndUFIVifRWnSyo4XaLnVEkFZZVV9ArzopWnU6OfXwghrEWlKDfWFEzHjx8nJCSErKwsWrVqZe1wmlTBuQpSsgrMy87MAgrLKi+p5+9sxz3+J7nJKZv2HMWn9CCa/P1QVVb7gV38TYPX4l6HVj1MZYZK06C2K0wcoq8ycKa0gtMlFZwq0ZuScKm+et302VxeUkGFwVjrcWJauTOscyDDOwcQ5uNc53YRQoimVpdcZBOJ+pNPPuG9994jJyeHmJgYPv74Y3r37l1r3aSkJB5++GGLMp1OR3l5+TWd60ZO1BdTFIVjp89Vd5ebkvfek0VUGS1/JVQqaO/rRJx/CTc5Z9NelYFX8QFUuWlQfNJcz/joSgo9O3O6VI9m61xCdr5HevC9LG31NKdL9Jwu1qMtPMzecm9ySw0Ul1fVOWYXnR3eLlq8nbUoQEpWgcVsnx0C3bitcwDDuwQQ7uda36YRQohGVZdcZPWu7x9++IHJkyfz2Wef0adPH2bNmkV8fDzp6en4+dX+OJGbmxvp6enmdZVM91gvKpWKNj7OtPFx5p7upl+U8koDe04WsjOzwNxlfqKgjH1559iXp+ZjgoFgnLUD6dLKHVfXMhyLjuBZdoxfPj1GiTEbgBl2G3jI7hxrDhfwUfpBAHw5y1aHBCoVDRmKP4ftgzhCMLna1px1asM5t7a4uHni7azF20WHt4sWHxct3s46fFx1eDtrcbC3vEeeX6znr705LE7NYeOR0+zLLmJfdhHvJx8gws+F4Z0DGN4lkPYBrvJ7IoRolqx+Rd2nTx969erF7NmzATAajYSEhPDUU0/x0ksvXVI/KSmJSZMmUVBQUK/zyRV13eUVVw9Uq07cu48XUFphuGx9d0d7/J1VdHI4g6OzKxrP1ni7aIk0HGTolkexM5y7/Mlcg8A30tSVXrOE9AF7h6vGeba0guS9uSxKy2b9oVNUGs7/aod5OzG8i6l7vEuwuyRtIYRVNZuu74qKCpycnPj5558ZOXKkuXzs2LEUFBTw22+/XbJPUlISjz76KMHBwRiNRrp3785bb71Fp06daj2HXq9Hr9eb10+cOEHHjh0lUV8Hg1HhYF4xqccLsdOo8HauufrV4emkRWt3hTfTGo2m7vL8dDh1EE5V/8xPh9K82veZcvD8y1rSfoWCTIi4Ffxr/28OUFhWyfJ9uSxOy2H1gXwqqs7f3w72cDRfaXcL8UCtlqQthGhazabr+9SpUxgMBvz9/S3K/f392b9/f637REVF8dVXXxEdHU1hYSEzZ86kX79+7Nmzp9Yvm5iYyOuvv94o8d+oNGoV7QPcaB/gVved1Wpwb2VawodYbis7W528D1Qn8gNQnAPOvufr7P7BNBJd63w+UZ85Cjv/a3oWPLgHuPrj7mjPPd1bcU/3VpToq1i5P4/Fadms3J/PiYIyvlx3lC/XHSXAzYFhnQMY1jmAXmFeaCRpCyFsjFWvqE+ePElwcDAbNmygb9++5vIXXniB1atXs3nz5qseo7Kykg4dOjB69GjeeOONS7bLFXULs2UuZG6Cvk+akjLAjm/g94nn67iHQHD384k7sCvoXAAoqzCw+kAei9NyWL4vjxL9+QFtPi5ahnYK4LbOgfRp64W9RuasEUI0jmZzRe3j44NGoyE3N9eiPDc3l4CAgGs6hr29Pd26dePQoUO1btfpdOh05yeoKCoqqn/Awvp6P2ZaLuTdDrr9A07sgLx9UJhlWvZW3zpRqcG3AwR3xzG4B8OCezDs/i6UG1WsP3SKRak5JO/N4VRJBd9tzuS7zZl4ONkztKM/wzsH0j/c58rd+UII0Yismqi1Wi09evRg+fLl5nvURqOR5cuXM3HixCvvXM1gMJCamsptt93WiJEKmxbaz7QA6Ishexcc3wYntpuSd9FxyNtjWnZ+Y6oX1A2HCasY0sGfIR38qSjwY2OuhiV7cli6J5czpRX8uO04P247jquDHXEd/BneOYBBkb6XjDwXQojGZPXHsyZPnszYsWPp2bMnvXv3ZtasWZSWlpqflX7ooYcIDg4mMTERgBkzZnDTTTcRHh5OQUEB7733HhkZGTz66KPW/BrCVuhcIWyAaalRnFOdtLefT94XDkQzVKKd3ZXBWhcGP76ON+7qzJajZ1iaepxFe0+RX6xnwc4TLNh5Aiethlva+zG8cyADwn1w0mmwU6tkFLkQotFYPVGPGjWK/Px8pk6dSk5ODl27dmXJkiXmAWaZmZmo1ee7Hc+ePctjjz1GTk4Onp6e9OjRgw0bNtCxY0drfQVh61wDoP3tpgVMI88rS89vP3MUjAYwVoKLP3ZqNf3CfeiX8gLTXVM4E9KZLZVt+CXHn7XFgfyxO5s/dmdbnEKrUWOvUWFvp8Zeoz6/rjGt29up0V64rlGjtVNhpz7/2WJbTV27i9YvOJavq45If1dcHeybsDGFEE3N6s9RNzV5jlrUqrLc9NiXb+T5slnRUJBhUc2otifXMZyN+lC2lLUiR/EkT/EkV/HkDK4oNP297GAPR6ICXE2Lv+lnW19ndHbSRS+ErWo2z1FbgyRqcc3OnYGTO01d5Se2me57nzt12eqK2o78AW9wqv0/qDQYURVk4nHoV0pcwjgZPJxKg5EKg5HKKiOVRoVKg5FKQ/XPKmP19pry6vWqi9YNCpVVpuOcOFtGTlHtr861U5veOhcZ4Ep7f1fTzwBXQjyd5LlxIWxAsxn1LYRNc/IyPetd87y3ophGk5/Ybkra+elQkgPFuVCaj8pYhZ+vH35B1c+Xl26AXR9AUHc63jru/HFn94KKc6Yu+QsXr0BwqVkPNJ3/Kve+C85VcCC3hPScItJzi0nPKWZ/TjHF5VUczCvhYF4Jf3K+m97RXkOkvwtRAa5E+rvSPsCNyAAXfF10cp9dCBsliVqIa6VSgUdr09LpbstthkooyQOHC14C4+oP3R401a+hKFCQZZqJrOj4lc+ntj+fxAc+B1HDTeWlp+BkCniE4OEbRe82XvRu43XBKRRyispJzyk+v+QWczCvhLJKA7uOF7LreKHFqbyctUT6u5gSd3X3eVSAKy46+SdCCGuT/wuFaAgae3APtiyreeHKxZ7aZhqJXpwDxdlQkmv6WVx9dV6cbepiN1aefya88oL3o2dugh/GQKve8Gjy+fK5t0CVHpWTF4GOXgQ6eRHr5A2tvaC9FwYHT7IrXThUrGVPgT2p+UYO5JVw7HQpZ0or2HTkDJuOnLH8Ch6OtA8433Ue6e9KO1+Xej9XrigKBqNClfHin0bTT0Pt5YaL6jvYa+T1r+KGIYlaiKakUp1/heqVVFWY3n1ek9CDu5/fptaAXyfwDrfcJ3fv5ecMBzRAq+olFkzzhd8xi/Iuf+dQXgknD+7Ed8+/2VcZyEfn4skpKudEQRnuhfs4mq5lvuJCIS6o1RpCvZ1wsNfUmkTNSdeoYDBYlhsbcERMO19n/m9wO0Z2DZYX0ogWTQaTCdESKIpp4FvZGTh3Fs6drv585qLPZ0yfa67Q7/sKOt9r+rz3d/jxQdNsZeP/ouBcBek5xXT+4Sac9aYJU4yoKFKcOKu4UIYDeuwpV7Smn5h+6hV7FhgHsNFoelY9kNPcodlInuLBb8bzz7f3Uu3HTmVAr9ijR0uVumZxoEqlxaDWYVTbo9Go0ahV2KlV1T/VnCwoo7j69a+B7g48OrAtf+sVgrN01YtmQgaTCXGjUaksr7qvprLMlLQd3M+X+UTCza+aZyrzcNLSp603uHlBkR70hahR8FCV4qEqvcyBTQYNGk5J58HYqVU4HV+L38LvqPLpwNRx07FTq9FoVDh9MQ316YOXP4gRMKoAB1DpQO0I/Z+Bm56guLyS+RsPs3/drywrbMcbf5Tz8YqDjO0bxrh+YXg6a6+9LYSwcZKohbgR2Tteek/dr71puVhC9eQ4hkrTDGfmq/IyqCqvXvTV63qoKicgvD/4mSZCoaoVRI/CzjUQb5fz793Hq62pG/+C/cyLmWLqzq8qg/IC8zZXB3seiyiB1e+gd/Ug3n4ex86U8eHyg3yzZi939Y7gsYFtCfJwbLAmE8JaJFELIa6Nxt50tV0zN/i1CugM93xxafmYH2uvryhgqLgogetNydrlgilxywvBJwqdTwTLH7iZJWk5fLryIJ+feZjyrVpWb+mAsXU/+g0ZQZu2UXWLWQgbIveohRDNm6HS9EcEoBSeQPXBpa8TzrcLRN2mP94db4Gw/uARetVn1IVoTHKPWghx49Ccf9e5yj0YXjgKmZvIS13OuUNrCSk/gG9VNhz82bQAilswqtD+plnXwgaYRtBL4hY2ShK1EKJlcfKC9rfh19409e3h4ydZ+df/qDq6jl6qfUSrjmBfdAJSfzQtAM/uOf/I3Lkz4OABannkS9gGSdRCiBatXasg2j3yf5wseIgv1x7l0S0H6WDYTx/1fgZr02njWIaDcyDmYW4LHofjW+DO2dDhDmuGbhNK9FUczivhUF4Jh/JLyDpzDju1Cgd7zQWLGscLPl+4zfGCMkd7DboLPttr5I+hayGJWghxQwjycGTqiI48dUs4/9nYgXkbjvHBuUpU54z4vrOS8QPa8PfeIbjmpJpGt184Kj7tV9j1vamrPLQ/BHYFu5bzCJiiKJwqqTAn45rEfDi/hOzC2id+aQgatQoHOzWOWg06u+qEr9XgYGf5R8CFCd/LWUf/cG86B7nfMG+mk8FkQogbUqm+ivlbs/hy7RFzMnJ1sGNcn2DGtyvEo10f0FRfy/yWADv/e35ntZ3p8TKfyIuWcMtn022M0ahw/GwZh/KLTYk4r5RD+aakXFhWedn9fFx0hPs5E+7nQpi3MwBlFQbKqwyUVxopqzRQXmlAf8Hn8koDZZVG9ObPprrlVQYaIut4O2sZFOlLbJQvAyN88Wpmz87LNJdXIIlaCHGhiiojv6Wc4LPVhzmcb3qRi85OzQM9Q5gwqC0hXk6Qtw8Or4SM9aal7OzlD+gSAD4R0P52uOmJ8+WK0mQD1vRVBo6eKjUl4uqr5EN5JRzJL0FfZax1H5UKQjydCPdzoZ2vKSmH+7kQ7uuKu5N9rfvUh6Io6KuM6KuTtkXCr/6svzCxX/BZX2n6XhsOn6ak+s10NbHHtPIgNsqXwZG+RLfyQGPjV9uSqK9AErUQojZGo0Lyvlw+XXWYXVkFgKlrdkR0II/HtqN9gFtNRSg+aZrm9NRBOHWgejlomva0Rs9H4I4PTJ8rSmFmpOkq/JGloHUylRfnmq7A7R3qFXNReaXF/eOaz5lnzl32vepajZq2vs6083WhnTkZu9DW1xkHe0294mhqFVVGtmecZdWBPFan57M/p9hiu6eTvflqe1CEr+WLdmyEJOorkEQthLgSRVHYeOQ0c1YdZu3BU+byW9r78URsO3qFeV1+5/JCOHXIlLi92kDrm0zl2bvg80Hg5AMvHKbSYOoi1s0fhfbYCirdQihza0epa1uKXNpw1imMU7pQClVulFeZrjTLqq8syyoMZJ45x6G8EvKK9ZcNxVVndz4RVyfjcD8XQrycbP5qs65yCstZfSCPVen5rDt4yvweeDBdbXcJdic20pfBUX50DbGNq21J1FcgiVoIca3SThQyZ/VhFqVmm++r9gz15I7oQKqMpi7cC5No+UUJtabbtrKiEq/Kk7hUnmF9ZSRV1Ze7f2pfppM647LnP6u4cFgJ4rAxiENKEIeVIFKNbcjHEwAdFUS5lBHi44Z3YJg5IUfZ5+KlM6JSjKAYTb0AihEUAxgN5z9fuM27nWkBU9f+4RWg0VmOfE9fbJqG1Vh9HGPVBctl1kP7QaeRpv3PnYFFUwAV3Pfv88dd8SZkbrzCMSvPr2u0pufeI26FPv93SZtVGozsyDjL6gP5rErPZ292kcV2d0d7Bkb4EBvlx+BIX3xdrXO1LYn6CiRRCyHq6uipUr5Yc5hftp+gwlD7Pd76UKkUWtmX0N4uhwh1Nu3UJwlTThBiPI6PIQ81l/7zvCEsgROdnyDcz4XI0m04/3Af+HeGJ9afr/RRdzhzuG7B3PwqDH7e9DknFT4bYHpl65QD5+v8eyhkba7bcXv/H9z2rulzcQ68HwUqDUy7YO7z+WNg/x91O27XMTDyU9Pnqgr4MMb0h8bfvgOH6tsUFaXklalZdfAUqw/ks/ZAPkXlVRaH6RzsRmykH4OjfOkW4oFdEz0yJm8mE0KIBtTGx5nEe6KZFBfJfzYc42BeCY7Vjww5as8/L+yoVVs8P3zp9vPlOns1Ojs1qssNMKs4Z0q2Nfe/q++F9+s7CKJCTHWOOoCdg8Xb2QBw9oGKElCpTUlRpTa9wMViXVP9WWX6fOE73LUuEDYQHD0tjxvaz9R9r9aYRr5r7E0/a9bNywXrrXqd31/nBsPeNpVfqG8CdL7nMsewtyyrKKm+tdD2/P5njpjGDeiLQed6vnzB/+F3ZDUP+ETygG8UhiERHCGY1ae9+D3Tjt0nS0k7UUTaiSJmrzyEm4MdAyN8GRzlS2ykL35u9Rs70NDkiloIIUTzVqWH3DQoyYeoYefLP7kJ8vfVvo9GR5VXO7LtQ0nV+7PqjCe7yv05qgRSgekPnw6BbsRWJ+3uoZ4N+oIW6fq+AknUQghxg6jSw+nDcCod8g9U/6werW+ofSDeplaPkFh+L7tPFOKuFHOLeifpSgiZ2ggGRPgwONKXO2KCcNFdX4e0dH0LIYQQdjrw72haLmQ0QEHGBcn7AOTvh1MHuKlPf37rMoDTJXr2r/uV/ps+4wjB3FL+HovTcli6J4f4TgHQhGPQJFELIYS4sag1pnvcXm0tu8oVxTQCHvB20dE/MghyBhLm1Y6F3fqzKj2P3KJyPJv4LWg28Ub0Tz75hLCwMBwcHOjTpw9btmy5Yv2ffvqJ9u3b4+DgQJcuXVi0aFETRSqEEKLFqhlYV6PtYBj3B+o7P6RriAeT4iJJvCe6ycOyeqL+4YcfmDx5MtOmTWPHjh3ExMQQHx9PXl5erfU3bNjA6NGjGT9+PDt37mTkyJGMHDmStLS0Jo5cCCGEaHxWH0zWp08fevXqxezZswEwGo2EhITw1FNP8dJLL11Sf9SoUZSWlvLHH+efubvpppvo2rUrn3322VXPJ4PJhBBCWFtdcpFVr6grKirYvn07cXFx5jK1Wk1cXBwbN26sdZ+NGzda1AeIj4+/bH0hhBCiObPqYLJTp05hMBjw9/e3KPf392f//v217pOTk1Nr/ZycnFrr6/V69Przw/CLi4trrSeEEELYIqvfo25siYmJuLu7m5eOHTtefSchhBDCRlg1Ufv4+KDRaMjNzbUoz83NJSAgoNZ9AgIC6lT/5ZdfprCw0Lzs3bu3YYIXQgghmoBVu761Wi09evRg+fLljBw5EjANJlu+fDkTJ06sdZ++ffuyfPlyJk2aZC5LTk6mb9++tdbX6XTodOefTC8oKAAgOzu7Qb6DEEIIUVc1OchovIZJXhQrmz9/vqLT6ZSkpCRl7969yoQJExQPDw8lJydHURRFefDBB5WXXnrJXH/9+vWKnZ2dMnPmTGXfvn3KtGnTFHt7eyU1NfWazrdlyxYFkEUWWWSRRRarL1u2bLlq3rL6m8lGjRpFfn4+U6dOJScnh65du7JkyRLzgLHMzEzU6vM99P369eO7777j1Vdf5Z///CcREREsXLiQzp07X9P5unXrxpYtW/D397c4bn0UFxfTsWNH9u7di6ur69V3uMFJe9WdtFndSHvVjbRX3TRkexmNRnJzc+nWrdtV61r9OermrKioCHd3dwoLC3Fzc7N2ODZP2qvupM3qRtqrbqS96sZa7dXiR30LIYQQzZkkaiGEEMKGSaK+DjqdjmnTplmMKheXJ+1Vd9JmdSPtVTfSXnVjrfaSe9RCCCGEDZMraiGEEMKGSaIWQgghbJgkaiGEEMKGSaK+Dp988glhYWE4ODjQp08ftmzZYu2QbNaaNWsYMWIEQUFBqFQqFi5caO2QbFZiYiK9evXC1dUVPz8/Ro4cSXp6urXDsllz5swhOjoaNzc33Nzc6Nu3L4sXL7Z2WM3G22+/jUqlsngts7A0ffp0VCqVxdK+ffsmO78k6nr64YcfmDx5MtOmTWPHjh3ExMQQHx9PXl6etUOzSaWlpcTExPDJJ59YOxSbt3r1ahISEti0aRPJyclUVlYydOhQSktLrR2aTWrVqhVvv/0227dvZ9u2bdxyyy3cdddd7Nmzx9qh2bytW7fy+eefEx0dbe1QbF6nTp3Izs42L+vWrWu6k9f97dxCURSld+/eSkJCgnndYDAoQUFBSmJiohWjah4AZcGCBdYOo9nIy8tTAGX16tXWDqXZ8PT0VL788ktrh2HTiouLlYiICCU5OVkZPHiw8swzz1g7JJs1bdo0JSYmxmrnlyvqeqioqGD79u3ExcWZy9RqNXFxcWzcuNGKkYmWqLCwEAAvLy8rR2L7DAYD8+fPp7S09LIz6gmThIQEbr/9dot/x8TlHTx4kKCgINq2bcuYMWPIzMxssnNbfVKO5ujUqVMYDAbzxCE1/P392b9/v5WiEi2R0Whk0qRJ9O/f/5onnrkRpaam0rdvX8rLy3FxcWHBggV07NjR2mHZrPnz57Njxw62bt1q7VCahT59+pCUlERUVBTZ2dm8/vrrDBw4kLS0tCaZzEQStRA2LCEhgbS0tKa9H9YMRUVFkZKSQmFhIT///DNjx45l9erVkqxrkZWVxTPPPENycjIODg7WDqdZGD58uPlzdHQ0ffr0ITQ0lB9//JHx48c3+vklUdeDj48PGo2G3Nxci/Lc3FwCAgKsFJVoaSZOnMgff/zBmjVraNWqlbXDsWlarZbw8HAAevTowdatW/nwww/5/PPPrRyZ7dm+fTt5eXl0797dXGYwGFizZg2zZ89Gr9ej0WisGKHt8/DwIDIykkOHDjXJ+eQedT1otVp69OjB8uXLzWVGo5Hly5fLfTFx3RRFYeLEiSxYsIAVK1bQpk0ba4fU7BiNRvR6vbXDsElDhgwhNTWVlJQU89KzZ0/GjBlDSkqKJOlrUFJSwuHDhwkMDGyS88kVdT1NnjyZsWPH0rNnT3r37s2sWbMoLS3l4YcftnZoNqmkpMTir8+jR4+SkpKCl5cXrVu3tmJktichIYHvvvuO3377DVdXV3JycgBwd3fH0dHRytHZnpdffpnhw4fTunVriouL+e6771i1ahVLly61dmg2ydXV9ZLxDs7Oznh7e8s4iMuYMmUKI0aMIDQ0lJMnTzJt2jQ0Gg2jR49ukvNLoq6nUaNGkZ+fz9SpU8nJyaFr164sWbLkkgFmwmTbtm3cfPPN5vXJkycDMHbsWJKSkqwUlW2aM2cOALGxsRbl8+bNY9y4cU0fkI3Ly8vjoYceIjs7G3d3d6Kjo1m6dCm33nqrtUMTLcTx48cZPXo0p0+fxtfXlwEDBrBp0yZ8fX2b5Pwye5YQQghhw+QetRBCCGHDJFELIYQQNkwStRBCCGHDJFELIYQQNkwStRBCCGHDJFELIYQQNkwStRBCCGHDJFELIYQQNkwStRCi0ahUKhYuXGjtMIRo1iRRC9FCjRs3DpVKdckybNgwa4cmhKgDede3EC3YsGHDmDdvnkWZTqezUjRCiPqQK2ohWjCdTkdAQIDF4unpCZi6pefMmcPw4cNxdHSkbdu2/Pzzzxb7p6amcsstt+Do6Ii3tzcTJkygpKTEos5XX31Fp06d0Ol0BAYGMnHiRIvtp06d4u6778bJyYmIiAh+//1387azZ88yZswYfH19cXR0JCIi4pI/LIS40UmiFuIG9tprr3Hvvfeya9cuxowZw9/+9jf27dsHQGlpKfHx8Xh6erJ161Z++uknli1bZpGI58yZQ0JCAhMmTCA1NZXff/+d8PBwi3O8/vrrPPDAA+zevZvbbruNMWPGcObMGfP59+7dy+LFi9m3bx9z5szBx8en6RpAiOZAEUK0SGPHjlU0Go3i7Oxssbz55puKoigKoDz++OMW+/Tp00d54oknFEVRlC+++ELx9PRUSkpKzNv//PNPRa1WKzk5OYqiKEpQUJDyyiuvXDYGQHn11VfN6yUlJQqgLF68WFEURRkxYoTy8MMPN8wXFqKFknvUQrRgN998s3l+6xpeXl7mz3379rXY1rdvX1JSUgDYt28fMTExODs7m7f3798fo9FIeno6KpWKkydPMmTIkCvGEB0dbf7s7OyMm5sbeXl5ADzxxBPce++97Nixg6FDhzJy5Ej69etXr+8qREsliVqIFszZ2fmSruiG4ujoeE317O3tLdZVKhVGoxGA4cOHk5GRwaJFi0hOTmbIkCEkJCQwc+bMBo9XiOZK7lELcQPbtGnTJesdOnQAoEOHDuzatYvS0lLz9vXr16NWq4mKisLV1ZWwsDCWL19+XTH4+voyduxY/vvf/zJr1iy++OKL6zqeEC2NXFEL0YLp9XpycnIsyuzs7MwDtn766Sd69uzJgAED+Pbbb9myZQv//ve/ARgzZgzTpk1j7NixTJ8+nfz8fJ566ikefPBB/P39AZg+fTqPP/44fn5+DB8+nOLiYtavX89TTz11TfFNnTqVHj160KlTJ/R6PX/88Yf5DwUhhIkkaiFasCVLlhAYGGhRFhUVxf79+wHTiOz58+fz5JNPEhgYyPfff0/Hjh0BcHJyYunSpTzzzDP06tULJycn7r33Xv71r3+ZjzV27FjKy8v54IMPmDJlCj4+Ptx3333XHJ9Wq+Xll1/m2LFjODo6MnDgQObPn98A31yIlkOlKIpi7SCEEE1PpVKxYMECRo4cae1QhBBXIPeohRBCCBsmiVoIIYSwYXKPWogblNz1EqJ5kCtqIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwoZJohZCCCFsmCRqIYQQwob9f2WD9xO4RH1PAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37211d39-451b-451f-9aeb-f06ff67639f0",
   "metadata": {},
   "source": [
    "As we can see based on the sharp downward slope, the model is learning well from the training data, and there is little to no indication of overfitting; that is, there is no noticeable gap between the training and validation set losses)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "77573bad-b187-45df-a5d8-7c9b7c079933",
   "metadata": {},
   "source": [
    "Using the same plot_values function, let's now also plot the classification accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c39be6ac-b048-4087-8b3e-f2f647fc8d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "062ad368-17bf-4d7b-b163-97bded678db7",
   "metadata": {},
   "source": [
    "Based on the accuracy plot, the model achieves a relatively high training and validation accuracy after epochs 4 and 5.\n",
    "\n",
    "However, it's important to note that we previously set eval_iter=5 when using the train_classifier_simple function, which means our estimations of training and validation performance were based on only 5 batches for efficiency during training.\n",
    "\n",
    "Now, we will calculate the performance metrics for the training, validation, and test sets across the entire dataset by running the following code, this time without defining the eval_iter value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a051427-d95b-4e01-af05-2d6905a01b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.21%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a452d34-260a-434a-b06a-b8eeb54284d9",
   "metadata": {},
   "source": [
    "The training and test set performances are almost identical.\n",
    "\n",
    "A slight discrepancy between the training and test set accuracies suggests minimal overfitting of the training data.\n",
    "\n",
    "Typically, the validation set accuracy is somewhat higher than the test set accuracy because the model development often involves tuning hyperparameters to perform well on the validation set, which might not generalize as effectively to the test set.\n",
    "\n",
    "This situation is common, but the gap could potentially be minimized by adjusting the model's settings, such as increasing the dropout rate (drop_rate) or the weight_decay parameter in the optimizer configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1576fd-2f08-4395-bce5-7fb0d4cfa30d",
   "metadata": {},
   "source": [
    "## USING THE LLM AS A SPAM CLASSIFIER"
   ]
  },
  {
   "cell_type": "raw",
   "id": "564aefb0-ddf9-4efd-9c96-cd5af4f2d5fc",
   "metadata": {},
   "source": [
    "After finetuning and evaluating the model in the previous sections, we are now in the final stage of this chapter: using the model to classify spam messages."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef337706-644f-4119-af7f-d3c26ce28a74",
   "metadata": {},
   "source": [
    "Finally, let's use the finetuned GPT-based spam classification model.\n",
    "\n",
    "The following classify_review function follows data preprocessing steps similar to those we used in the SpamDataset implemented earlier in this chapter.\n",
    "\n",
    "And then, after processing text into token IDs, the function uses the model to predict an integer class label, similar to what we have implemented earlier, and then returns the corresponding class name:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dcad5793-b70e-4835-97d5-edaee5d3acca",
   "metadata": {},
   "source": [
    "Step 1: Prepare inputs to the model\n",
    "\n",
    "Step 2: Truncate sequences if they too long\n",
    "\n",
    "Step 3: Pad sequences to the longest sequence\n",
    "\n",
    "Step 4: Add batch dimension\n",
    "\n",
    "Step 5: Model inference without gradient tracking\n",
    "\n",
    "Step 6: Logits of the last output token\n",
    "\n",
    "Step 7: Return the classified result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e592d364-758f-4d19-b905-1589c19e6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "66d93c02-4848-4965-ace1-171d35b992d5",
   "metadata": {},
   "source": [
    "Let's try this classify_review function on an example text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3f95488-3bfd-4459-ae45-605765e73a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3e753be-ba8b-4af9-8fe8-967e120a03bf",
   "metadata": {},
   "source": [
    "The resulting model correctly predicts \"spam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48c59778-ad56-470d-aed9-a57c2e867595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14872c95-792d-4bb2-acb1-750f910cb919",
   "metadata": {},
   "source": [
    "Also, here, the model makes a correct prediction and returns a \"not spam\" label."
   ]
  },
  {
   "cell_type": "raw",
   "id": "81672898-b703-412e-ad13-0cb2e08182b9",
   "metadata": {},
   "source": [
    "Finally, let's save the model in case we want to reuse the model later without having to train it again using the torch.save method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "151f5893-b49b-4341-94cf-550799798976",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0316775d-ca80-4853-9128-5576ff918db5",
   "metadata": {},
   "source": [
    "Once saved, the model can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47c2679a-3f1a-494a-8bbd-191a8c70a9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\")\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeae50c7-6dc1-4627-8b67-731cc3706800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
